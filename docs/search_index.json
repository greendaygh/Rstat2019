[
["index.html", "R로 배우는 기초통계 Chapter 1 Introduction 강의 개요 1.1 Goal 강의 목표 1.2 References 참고 자료 1.3 Evaluation 평가 세부 항목 1.4 Schedule 강의 계획 1.5 References 참고 자료", " R로 배우는 기초통계 한국생명공학연구원 김하성 2019-11-20 Chapter 1 Introduction 강의 개요 장소: 한국생명공학연구원 연구동 세미나실 1213호 (매주수요일 13:00~16:00) 강사: 한국생명공학연구원 바이오합성연구센터 김하성 연락처: 042-860-4372, haseong@kribb.re.kr (생명연 연구동 1143) 강의site: https://greendaygh.github.io/Rstat2019/ 1.1 Goal 강의 목표 이공계열 대학원생이 보다 쉽게 통계 이론을 습득하고 활용하는 능력을 배양하는데 주요 목적이 있음. 특히 데이터 분석용 프로그래밍언어인 R을 기반으로 한 실습을 통하여 프로그래밍 기술 습득과 함께 데이터를 다루는 능력을 배움으로써 이공계 연구에 있어서 필수인 통계적 사고의 기초를 다지는데 그 목적이 있음. 1.2 References 참고 자료 Using R for Introductory Statistics by John Verzani Free version of 1st Edition https://cran.r-project.org/doc/contrib/Verzani-SimpleR.pdf http://cbb.sjtu.edu.cn/~mywu/bi217/usingR.pdf Second edition https://www.crcpress.com/Using-R-for-Introductory-Statistics-Second-Edition/Verzani/p/book/9781466590731 R for Data Science (https://r4ds.had.co.nz, https://github.com/hadley) https://resources.rstudio.com/ 일반통계학 (영지문화사, 김우철 외) 1.3 Evaluation 평가 세부 항목 출석 50% / 과제 50% / 80점 이상 S, 80점 미만 U 부여 1.4 Schedule 강의 계획 1주차- R basics / introduction of data 2주차 - Univariate data – Summary statistics 일변량자료 (범주형, 수치형, 분포) 3주차 - Bivariate data – Correlation / Independence 이변량자료 (자료비교, 수치자료의 관계, 단순선형회귀) 4주차 - Multivariate data – R data structure 다변량자료 (다변량, R자료형, R그래픽) 5주차 - Populations – Families of distributions 모집단과 분포 6주차 - Sampling – Distribution and CLT 시뮬레이션, 샘플링 7주차 - Statistical inference 통계적 추론 8주차 - Confidence intervals 신뢰구간 9주차 - Significance test - parameteric 유의성 검정 (모수) 10주차 - Significance test – non parametric 유의성 검정 (비모수) 11주차 - Goodness of fit - parametric 적합도 검정 (모수) 12주차 - Goodness of fit – non parametirc 적합도 검정 (비모수) 13주차 - Linear regression – basics &amp; simple LR 단순회귀모형 14주차 - Multiple linear regression 다중회귀모형 15주차 - Analysis of variance 분산분석 16주차 - Logistic / Non-linear regression 로지스틱/비선형회귀모형 9/25 휴강 (강사 해외 출장) 1.5 References 참고 자료 R 홈페이지 https://www.r-project.org/ Rstudio 홈페이지 https://www.rstudio.com/ Packages for biologists https://www.bioconductor.org/ R 기본 문서들 (소개, 사용, 설치, 운영) https://cran.r-project.org/doc/manuals/r-release/R-intro.html https://cran.r-project.org/doc/manuals/r-release/R-data.html https://cran.r-project.org/doc/manuals/r-release/R-admin.html R ebooks https://bookdown.org/ Cheat Sheets https://www.rstudio.com/resources/cheatsheets/ "],
["r-basics.html", "Chapter 2 R basics 2.1 What is R / Rstudio 2.2 R / Rstudio installation 2.3 Rstudio interface 2.4 Keyboard shortcuts 2.5 R programming basics and terminology 2.6 Set working directory 2.7 R coding practice 2.8 Variables and values 2.9 Variable type of (storage) mode 2.10 Variable - Vectors 2.11 Functions 2.12 Vectorized functions 2.13 Help 2.14 RStudio workspace 2.15 R packages 2.16 Data sets 2.17 Cheatsheet", " Chapter 2 R basics 2.1 What is R / Rstudio R is a programming language that runs computations (https://www.r-project.org/) RStudio is an integrated development environment (IDE) that provides an interface for the programming (https://www.rstudio.com/) 2.2 R / Rstudio installation Install R first and then install RStudio second R Rstudio 2.3 Rstudio interface 2.4 Keyboard shortcuts 참고사이트 https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts Tools –&gt; Keyboard shortcut Quick Reference (Alt + Shift + K) 코드편집창 이동 (Ctrl+1) 콘솔창 이동(Ctrl+2) 한 줄 실행 (Ctrl+Enter) 주석처리 (Ctrl + Shift + C) Starting with a hashmark (‘#’), everything to the end of the line is a comment 실습 코드편집창에서 다음 입력 단축키 Ctrl + enter로 코드 실행 단축키 Ctrl + 2로 커서 콘솔창으로 이동 x값 x+y값 확인 단축키 Ctrl + 1로 코드편집창 이동 단축키 Ctrl + Shift + C 사용 # x &lt;- 10 # y &lt;- 20 2.5 R programming basics and terminology Console: 명령어 입력하는 창 Code: R 프로그래밍 변수/제어문 모음 Objects (개체, variable): 값이 (데이터) 저장되는 장소 Data types: Integers, doubles/numerics, logicals, and characters. Object (Variable) types: Vectors: 값들의 모임 combine function c() EX: c(6, 11, 13, 31, 90, 92) Factors: 범주형 데이터 저장 장소 Data frames: 2D matrix 형태 데이터 자장 장소 Conditionals (조건, 제어): if: ==, &amp; (AND), | (OR) Ex: (2 + 1 == 3) &amp; (2 + 1 == 4) for, while: 반복 수 Functions (함수, commands): 특정 일 수행, 함수이름 - 입력값 (arguments) - 출력값 (output) 으로 구성 2.6 Set working directory 시작 전 항상 작업 디렉토리 설정 예를 들어 c: 아래 새로운 디렉토리 rstat01 을 만들고 작업공간으로 설정 getwd() dir() setwd(&quot;C:\\\\rstat01&quot;) getwd() dir() 또는 아래와 같이 RStudio 메뉴 에서 설정 2.7 R coding practice 콘솔 계산기 2 + 2 ((2 – 1)^2 + (1 – 3)^2 )^(1/2) 2 + 2; 2 - 2 이전 명령: 콘솔에서 위 아래 화살표 2.8 Variables and values R is a programming language Assignment operator ( &lt;- OR = ) Valid object name &lt;- value 단축키: Alt + - (the minus sign) 내장 변수 Built-in variables x &lt;- 2 y &lt;- x^2 – 2*x + 1 y x &lt;- &quot;two&quot; some_data &lt;- 9.8 pi 변수이름 작명법 Characters (letters), numbers, “_”, “.” A and a are different symbols Names are effectively unlimited in length i_use_snake_case &lt;- 1 otherPeopleUseCamelCase &lt;- 2 some.people.use.periods &lt;- 3 And_aFew.People_RENOUNCEconvention &lt;- 4 자동 완성 기능 (Tab completion) in RStudio 2.9 Variable type of (storage) mode 2.10 Variable - Vectors Combine function c(): Concatenating elements end to end x &lt;- c(10.4, 5.6, 3.1, 6.4, 21.7) y &lt;- c(&quot;X1&quot;, &quot;Y2&quot;, &quot;X3&quot;, &quot;Y4&quot;) 인덱싱: Subsets of the elements of a vector x[1] x[1:3] x[c(1,2,4)] y[3] 2.11 Functions Function define my_sine &lt;- function(x){ y &lt;- sin(x) return(y) } Usage my_sine(pi) Terminology function name: my_sine parameter: x argument: pi return value: y Built-in functions Arguments separated by commas Tab completion x &lt;- pi sin(x) sqrt(x) log(x) log(x, 10) x &lt;- c(10, 20, 30) x + x mean(x) sum(x)/length(x) 2.12 Vectorized functions x &lt;- c(10, 20, 30) x + x sqrt(x) sin(x) log(x) x-mean(x) 2.13 Help R의 장점 중 하나 (예제 포함) ? ?mean help(&quot;mean&quot;) example(&quot;mean&quot;) help.search(&quot;mean&quot;) help(package=&quot;MASS&quot;) 2.14 RStudio workspace 2.15 R packages R comes ready loaded with various libraries of functions called packages ex) sum() is in the “base” package and sd() in the “stats” package The packages can be found in numerous server locations on the web called repositories The Comprehensive R Archive Network (CRAN) http://cran.r-project.org/web/views/ Bioconductor specialised in genomics http://www.bioconductor.org/packages/release/bioc/ UsingR package installation UsingR package loading library(UsingR) R 설치 디렉토리 R 패키지 설치 디렉토리 .libPaths() path.package() 2.16 Data sets Packages include accompanying data sets R has a datasets package that is loaded automatically The data function produces a copy of dataset in user’s workspace head(rivers) length(rivers) class(rivers) data(rivers) data(package=&quot;UsingR&quot;) library(HistData) head(Cavendish) str(Cavendish) head(Cavendish$density2) 2.17 Cheatsheet "],
["univariat-data.html", "Chapter 3 Univariat data 3.1 Introduction 3.2 Data vectors 3.3 Data type 3.4 Functions 3.5 Numeric summaries 3.6 Center 3.7 Spread 3.8 Shape 3.9 Viewing the shape 3.10 Categorical data", " Chapter 3 Univariat data 3.1 Introduction Statistics 데이터 분석을 통한 예측 - 데이터를 수집, 정리하여 이로부터 미지의 사실에 대한 신빙성 있는 추론을 수행하는 과정 Data - 사실을 나타내는 수치 맥도너 정보경제학 (1963) 지혜 (wisdom) : 패턴화된 지식 지식 (knowledge) : 가치있는 정보 정보 (information) : 의미있는 데이터 데이터 (data) : 단순한 사실의 나열 Univariate: Single variable Data collection process Case: One of several different possible items of interest Variable: Some measurement of a case Univariate data set: A set of measurements for a variable \\[ x_1, x_2, ..., x_n \\] library(UsingR) exec.pay ?exec.pay Levels of measurement Nominal (명목형) – 사람 이름 Ordinal (순서형) – 달리기 도착 순서 Interval (구간형) – 선수1, 선수2 종점통과 시간 Ratio (비율형) – 출발시간 기준 종점 통과 시간 Data type in R Numeric data types Discrete (이산형) data - 카운트, 횟수 Continuous (연속형) data - 키, 몸무게, Cannot be shared Factors data - Categories to group the data Character data - Identifiers Date and time Hierarchical data - 네트워크 구조 3.2 Data vectors Using combine function #The number of whale beachings in Texas during the 1990s whale &lt;- c(74, 122, 235, 111, 292, 111, 211, 133, 156, 79) #Object `whale` is a data vector == (univariate) data set # The size length(whale) sum(whale) sum(whale)/length(whale) mean(whale) Vectorization whale - mean(whale) whale^2 - mean(whale) sqrt(whale) Adding values to a vector variable x &lt;- 1 x &lt;- c(x, 2) x x &lt;- c(x, 3, 3, 3, 4) x Missing/NULL values NA: Not available, The value is missing NULL: a reserved value NaN: Not a number (0/0) Inf: (1/0) hip_cost &lt;- c(10500, 45000, 74100, NA, 83500) sum(hip_cost) sum(hip_cost, na.rm=TRUE) ?sum Attributes: names in data vectors head(precip) class(precip) length(precip) names(precip) order(names(precip)) test_scores &lt;- c(100, 90, 80) names(test_scores) &lt;- c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Shirley&quot;) Indexing head(precip) precip[1] precip[2:10] precip[c(1,3,5)] precip[-1] precip[&quot;Seattle Tacoma&quot;] precip[c(&quot;Seattle Tacoma&quot;, &quot;Portland&quot;)] precip[2] &lt;- 10 Functions for generating structured data 1:5 seq(1,5, by=1) seq(0, 100, by=10) seq(0, 100, length.out=11) ?seq rep(5, times10) rep(1:3, times=4) 3.3 Data type Numeric data class(1) class(pi) class(seq(1,5,by=1)) Character data ch &lt;- c(&quot;Lincoln&quot;, &quot;said&quot;, &quot;and&quot;) class(ch) Combining strings - paste function paste(&quot;X&quot;, 1:10) paste(&quot;X&quot;, 1:10, sep=&quot;&quot;) paste(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;) paste(c(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;)) paste(c(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;), collapse=&quot; &quot;) x &lt;- 1:10 paste(x) paste(x, collapse=&quot;:&quot;) Factors x &lt;- c(&quot;Red&quot;, &quot;Blue&quot;, &quot;Yellow&quot;, &quot;Green&quot;, &quot;Blue&quot;, &quot;Green&quot;) y &lt;- factor(x) y Adding a level levels(y) y[1] &lt;- &quot;Gold&quot; y levels(y) &lt;- c(levels(y), &quot;Gold&quot;) levels(y) y y[1] &lt;- &quot;Gold&quot; y Odered factors (ex. 위치 바꾸기) #library(UsingR) str(Cars93) x &lt;- Cars93$Origin plot(x) levels(x) &lt;- c(&quot;non-USA&quot;, &quot;USA&quot;) levels(x) plot(x) Logical data TRUE and FALSE “is” functions Comparison by &lt;, &lt;=, ==, !=, &gt;=, &gt; Combination by !, &amp;, | is.na(1) is.numeric(1) is.logical(TRUE) pi &lt; 3 precip &lt; 30 which(precip &lt; 30) any(precip &lt; 30) all(precip &lt; 30) any(39 == precip) which(39 == precip) sum(precip &lt; 30) sum(c(TRUE, TRUE)) x &lt;- Cars93$Origin x == &quot;USA&quot; which(x == &quot;USA&quot;) i &lt;- which(x == &quot;USA&quot;) x[i] x &lt;- 1:100 x &lt; 10 x &gt; 90 x &lt; 10 | x &gt;90 which(x &lt; 10 | x &gt;90) i &lt;- which(x &lt; 10 | x &gt;90) x[i] x[x &lt; 10 | x &gt;90] Date and time Unixtime, POSIX time 1970년 1월 1일 00:00:00 협정 세계시(UTC) 부터의 경과 시간을 초로 환산 32비트로 표현된 유닉스 시간은 1970년 1월 1일 00:00 (UTC)에서 2,147,483,647 (231 - 1) 지난 후인 2038년 1월 19일 03:14:08 UTC에 2038년 문제를 발생시킨다. 이는 산술 오버플로와 관련 있는 문제이다. –wiki- library(lubridate) current_time &lt;- now() # record since 1970 as.numeric(current_time) as.numeric(now()) month(current_time) 3.3.1 Example - Recoding values 다음은 신생아들의 키를 나타내는 data set 이다. 오류 값을 찾아내고 이들 값을 NA로 바꾼 후 평균 값을 구하라. x &lt;- babies$dwt x 3.3.2 Example - Average distance from center \\[\\begin{equation} (| x_1 - \\bar{x} | + |x_2 - \\bar{x}| + ... + |x_n - \\bar{x}| )/n \\end{equation}\\] x &lt;- rivers 3.4 Functions Define a function my_mean &lt;- function(x){ total &lt;- sum(x) n &lt;- length(x) return(total/n) } Write a function named get_dist for the example 3.3.2, and use it for the rivers data get_dist &lt;- function(x){ return() } 3.5 Numeric summaries 대푯값 Center – commonly known as “average” or “mean” but not the only one. median, mode, etc Spread – Variability of a data set. No variability – mean is everything Large variability – mean informs much less confidence of interpretation from knowing center Distance from center Shape – Degree of interpretation from knowing center and spread. eg. bell shape – two sides are equally likely, large values are rather unlikely and values tend to cluster near the center. 3.6 Center 3.6.1 Sample mean \\[ \\bar{x} = \\frac{1}{n} (x_1 + x_2 + ... + x_n) = \\frac{1}{n}\\sum_i{x_i} \\] head(kid.weights) str(kid.weights) wts &lt;- kid.weights$weight length(wts) plot(wts) mean(wts) devs &lt;- wts – mean(wts) # deviation, centering plot(wts) mean(wts) Trimmed mean mean(wts) wts[wts&lt;120] mean(wts[wts&lt;=120]) mean(wts, trim=0.8) 3.6.2 Measure of Position _p_th Quantile - 특정 값으로 이 값보다 작은 데이터의 비율이 100∙p 퍼센트, 큰 데이터의 비율은 100∙(1- p) 퍼센트 Median - Splits the data in half p=0.5 Percentiles - The same as quantile but its scale is 0 to 100 x &lt;- 0:5 length(x) quantile(x, 0.25) median(x) quantile(x, seq(0, 1, by=0.2)) quantile(x) Robustness mean(wts) median(wts) plot(wts) abline(h=mean(wts), col=&quot;red&quot;) abline(h=median(wts), col=&quot;blue&quot;) wts2 &lt;- wts[wts&lt;120] abline(h=mean(wts2), col=&quot;red&quot;, lty=2) Boxplot x &lt;- 0:5 quantile(x) boxplot(x) text(x=1.3, y=quantile(x, 0.25), labels = &quot;1사분위수&quot;) text(x=1.3, y=quantile(x, 0.5), labels = &quot;2사분위수&quot;) text(x=1.3, y=quantile(x, 0.75), labels = &quot;3사분위수&quot;) 3.7 Spread Range - the distance between the smallest and largest values Sample variance Distance - \\[ d_i = x_i - \\bar{x} \\] \\[\\begin{equation} s^2 = \\frac{1}{n-1}\\sum_i(x_i - \\bar{x})^2 \\end{equation}\\] Sample standard deviation 측정값들이 평균에서 떨어진 정도 \\[\\begin{equation} \\sqrt{s^2} = sqrt{ \\frac{1}{n-1}\\sum_i(x_i - \\bar{x})^2 } \\end{equation}\\] wts &lt;- kid.weights$weight var(wts) sd(wts) plot(wts) boxplot(wts) hist(wts) hist(wts, breaks = 50) hist(wts, 50) abline(v=mean(wts), col=&quot;red&quot;) z-score How big (small) is the value relative to the others \\(z=3\\) 이 값은 평균에 비해 3 표준편차만큼 크다 \\[\\begin{equation} z_i = \\frac{x_i - \\bar{x}}{s} \\end{equation}\\] Example - z score wts의 z 값을 구하는 함수를 만들고 histogram을 그리시오 wts &lt;- kid.weights$weight Interquartile range (IQR) Middle 50% of the data Difference between Q3 and Q1 Example - IQR wts 변수 값들의 IQR 을 구하시오 wts &lt;- kid.weights$weight 3.8 Shape Symmetry and skew \\[\\begin{equation} sample skewness = \\sqrt{n} \\frac{\\sum{(x_i - \\bar{x})^2}}{(\\sum{(x_i - \\bar{x})^2)^{3/2}}} = \\frac{1}{n}\\sum{z_i^3} \\end{equation}\\] myskew &lt;- function(x){ n &lt;- length(x) z &lt;- (x-mean(x))/sd(x) return(sum(z^3)/n) } wts &lt;- kid.weights$weight hist(wts, 50) myskew(wts) z &lt;- rnorm(length(wts)) hist(z, br=50) myskew(z) Sample excess kurtosis Measure of tails \\[\\begin{equation} sample excess kurtosis = n \\frac{\\sum{(x_i - \\bar{x})^4}}{(\\sum{(x_i - \\bar{x})^2)^2}} -3 = \\frac{1}{n}\\sum{z_i^4} - 3 \\end{equation}\\] mykurtosis &lt;- function(x){ n &lt;- length(x) z &lt;- (x-mean(x))/sd(x) return(sum(z^4)/n - 3) } wts &lt;- kid.weights$weight hist(wts, 50) mykurtosis(wts) z &lt;- rnorm(length(wts)) hist(z, br=50) mykurtosis(z) 3.9 Viewing the shape Dot plots – Trouble with repeated values, only used for small data sets Stem and leaf plot – Shows range, median, shape. But only for small data sets. trouble with clustered data. Rounding Histogram – Break up an interval, for each subinterval the number of data points are counted Density plots wts &lt;- kid.weights$weight xrange &lt;- range(wts) den &lt;- density(wts) plot(den, xlim=xrange, xlab=&quot;densities&quot;, main=&quot;&quot;) Boxplots It shows center, spread, shape Five-number summary of a univariate data set: min, max, Q1, Q3, and median These are good summary of even very large data sets. Outliers – 1.5 x IQR 3.10 Categorical data Tabulating data x &lt;- babies$smoke x &lt;- factor(x, labels=c(&quot;never&quot;, &quot;now&quot;, &quot;until current&quot;, &quot;once, quit&quot;, &quot;unknown&quot;)) table(x) out &lt;- table(x) prop &lt;- 100*out/sum(out) round(prop, digits=2) barplot(out) barplot(prop) dotplot(out) dotplot(prop) pie(out) "],
["bivariate-data.html", "Chapter 4 Bivariate data 4.1 Introduction 4.2 Data manipulation 4.3 Paired data 4.4 Bivariate categorical data 4.5 Homeworks", " Chapter 4 Bivariate data 4.1 Introduction 본 단원에서는 두 변수를 동시에 고려할 경우 각 변수가 가지고 있는 데이터를 비교하여 변수간의 유사성이나 관계 (상관, 독립)에 대한 설명하는 방법을 소개하며 짝데이터 (Paired data)나 범주형 데이터의 경우에 두 변수의 관계를 어떻게 설명하는지 알아봅니다. 또한 그래프를 이용하여 두 변수의 관계를 가시화 하는 방법에 대해 알아보겠습니다. 4.1.1 Independence samples 위 그림은 두 변수간 (x, y축) 관계를 산점도와 marginal histogram을 이용하여 비교한 그림 입니다. Marginal histogram은 두 그래프가 비슷한 모양을 하고 있지만 왼쪽 그림은 두 변수간 강한 양의 상관관계를 보여주고 있으며 오른쪽은 두 변수가 아무런 관계도 아닌 독립임을 보여줍니다. 두 변수간의 관계를 설명할 때 가장 일반적인 경우의 데이터 형태는 코흐트 데이터 입니다. 처리군과 대조군으로 이루어진 데이터를 말하며 플라시보 (Placebo effect) 효과를 방지하기 위해서 실제 효과는 없지만 대조군에 처리한 조건과 동일한 조건의 처리를 수행합니다. beets &lt;- c(41, 40, 41, 42, 44, 35, 41, 36, 47, 45) no_beets &lt;- c(51, 51, 50, 42, 40, 31, 43, 45) 위 데이터는 비트의 효과를 검증하기 위해 각 실험자의 달리는 시간을 측정하고 비교한 데이터 입니다. 이 데이터를 보고 알 수 있는 사실은 무엇이 있을까요? 우리가 앞서 단원에서 대푯값을 배웠으니 이를 고려해서 질문을 다시 생각해 봅시다. 가장 오래 달린 세 명이 no beet 그룹에 있음 가장 적게 달린 한 사람이 beet 그룹에 있음 center, spread 또는 shape가 유사한가? 이 후 단원에서 randomness가 가정된 상태에서 위 질문들에 대한 해답을 찾는 과정을 배우게 될 것입니다. 4.1.2 plot 두 변수에 대한 관계를 가장 먼저 그리고 가장 직관적으로 설명하는 방법은 그래프 입니다. 줄기잎 차트나 dot-plot 등은 많이 쓰이지 않으나 boxplot과 산점도는 (dot-plot) 데이터 분석을 수행하기 전에 변수들간의 관계를 대략적으로 가늠해 볼 수 있기 때문에 많이 사용되고 있습니다. dotchart(c(beets, no_beets)) dotchart(c(beets, no_beets), groups=factor(c(rep(&quot;beets&quot;, length(beets)), rep(&quot;no_beets&quot;, length(no_beets))))) boxplot에서는 대략 다섯 가지 대표값을 볼 수 있습니다. 1사분위수, 2사분위수(중간값), 3사분위수, 그리고 최대, 최소값입니다. 여기서 최대 최소는 IQR 1.5배에 해당하는 하위 또는 상위 값으로 그 범위를 벗어나는 값들은 outlier로 취급합니다. boxplot(beets, no_beets) boxplot(beets, no_beets, names=c(&quot;beets&quot;, &quot;no_beets&quot;)) Density plot은 histogram과 비슷하게 데이터의 center, spread, 그리고 shape를 모두 보여주는 높은 활용도 때문에 많이 사용되는 그래프 입니다. 지난 시간 R의 density 함수를 활용하여 그리는 방법을 간단히 알아본 바와 같이 density 함수는 밀도함수를 추정하고 주어진 범위의 x값과 그에 대한 y값을 반환해주며 plot 함수를 이용하여 x와 y위치에 점이나 선을 그려주어 그래프를 완성합니다. library(UsingR) head(michelson) ?michelson str(michelson) speed &lt;- michelson$Speed expt &lt;- michelson$Expt fourth &lt;- speed[expt == 4] fifth &lt;- speed[expt == 5] d4 &lt;- density(fourth) d5 &lt;- density(fifth) xrange &lt;- range(c(d4$x, d5$x)) yrange &lt;- range(c(d4$y, d5$y)) plot(d4, xlim=xrange, ylim=yrange, xlab=&quot;densities&quot;, main=&quot;&quot;) lines(d5, lty=2) legend(650, 0.008, legend=c(&quot;Fourth&quot;, &quot;Fifth&quot;), lty=c(1,2)) plot(fourth, fifth) QQplot은 두 변수가 갖는 데이터의 Quantile 값을 비교하는 그래프로 R의 qqplot 함수를 사용합니다. qqplot(fourth, fifth) ps &lt;- seq(0.05, 0.95, by=0.05) x &lt;- quantile(fourth, ps) y &lt;- quantile(fifth, ps) plot(x, y) o &lt;- order(fourth) fourth[o] fourth 4.2 Data manipulation 4.2.1 List R언어에서 두 변수를 담을 수 있는 데이터 타입은 list와 data frame 두 종류가 있습니다. list 변수 타입은 vector 형태의 여러개의 element를 가질 수 있으며 각 element의 데이터는 문자나 숫자 어떤 데이터 타입도 가능하며 각 element vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 [ ]는 리스트를 반환하고 [[ ]]는 vector element들을 반환합니다. b &lt;- list(beets = beets, &quot;no beets&quot;=no_beets) b$beets b[1] b[[1]] class(b[1]) class(b[[1]]) boxplot(b) 4.2.2 Data frame data.frame 타입 변수는 list와 같은 기능의 타입으로 볼 수 있지만 모든 element 들이 같은 길이를 갖는다는 것이 다릅니다. 따라서 2차원 메트릭스 형태로 표현될 수 있으며 matrix와 같이 [가로, 세로] 방식으로 인덱싱 할 수 있습니다. 각 row는 샘플을 나타내고 column은 하나의 변수를 타나냅니다. R 기반의 데이터 분석에서는 가장 선호되는 데이터 타입이라고 볼 수 있습니다. id &lt;- 1:10 name &lt;- paste(&quot;Name&quot;, id, sep=&quot;&quot;) grade &lt;- LETTERS[sample(1:5, size=length(id), replace=T)] student &lt;- data.frame(id, name, grade) student student$id student[,1] class(student$name) str(student) class(id) class(name) class(grade) class(student) class(student[,1]) class(student[,3]) student &lt;- data.frame(id, name, grade, stringsAsFactors = F) 4.2.3 Model formulas R에서는 두 변수의 관계를 수학적으로 표현하기 위한 방법을 제공하며 다양한 모형에서 공통적으로 사용될 수 있습니다. \\[ response(s) \\sim predictor(s) \\] head(michelson) beets no_beets runtime &lt;- c(beets, no_beets) nitrate &lt;- c(rep(&quot;beets&quot;, length(beets)), rep(&quot;nobeets&quot;, length(no_beets))) food.sports &lt;- data.frame(runtime, nitrate) boxplot(runtime~nitrate, data=food.sports) boxplot(michelson$Speed ~ michelson$Expt) boxplot(Speed ~ Expt, data=michelson) R에서 plot함수는 Generic function으로서 입력 파라메터가 갖는 데이터 타입에 따라서 다른 기능을 수행할 수 있습니다. 예를 들어 formula type으로 \\(x \\sim f\\) 가 들어갈 경우 그룹별로 boxplot을 나란히 그려주며 따라서 그룹별로 데이터가 얼마나 다른지 한 눈에 비교할 수 있습니다. plot(Speed ~ Expt, data=michelson) out &lt;- summary(Speed ~ Expt, data=michelson) plot(out) plot(michelson$Speed) plot(michelson$Speed, main=&quot;Speed&quot;, ylab=&quot;Speed&quot;, bty=&quot;l&quot;, pch=&quot;*&quot;, cex=2, col=&quot;red&quot;) ?pch Stack 함수는 관측 값을 하나의 벡터로 만들고 각 벡터의 라벨을 또 하나의 벡터로 만들어서 합해주는 기능을 수행합니다. 이는 다음에 배울 reshape2 패키지의 melt 와 비슷한 기능을 하고 있습니다. Split 함수의 경우 data를 정의된 그룹으로 나누고 list 타입으로 반환해줍니다. 그룹은 factor 형으로 정의된 변수에 저장되어 있어야 합니다. str(twins) boxplot(data.frame(twins$Foster, twins$Biological)) b &lt;- list(&quot;beets&quot; = beets, &quot;no beets&quot; = no_beets) stacked &lt;- stack(b) plot(values ~ ind, data=stacked) ?split speeds &lt;- split(michelson$Speed, michelson$Expt) names(speeds) &lt;- paste(&quot;Expt&quot;, 1:5, sep=&quot;&quot;) speeds speed &lt;- michelson$Speed expt &lt;- michelson$Expt speed expt speeds &lt;- list(speed[expt==1], speed[expt==2], speed[expt==3], speed[expt==4], speed[expt==5]) names(speeds) &lt;- paste(&quot;Expt&quot;, 1:5, sep=&quot;&quot;) speeds 4.2.4 Example 3-1 다음 데이터를 list 타입의 변수를 이용해서 저장하시오 marsha: 25, 0, 45, 90, 0 bill: 30, 30, 30, 30 holly: 15, 0, 90, 0 Hmisc 패키지를 읽고 michelson 데이터를 Speed ~ Expt model formular 를 사용해서 어떤 ouput이 나오는지 설명하시오 library(Hmisc) michelson summary(Speed~Expt, michelson) twins 데이터에서 Foster와 Biological 데이터에 대한 boxplot을 그리고 두 데이터의 center와 spread를 비교하시오 4.3 Paired data paired data는 두 종류의 변수에 대한 데이터를 하나의 샘플로 부터 얻을 때의 데이터를 말합니다. 본 단원에서 두 변수의 데이터형은 연속형과 연속형, 또는 연속형과 범주형의 경우로 다음 단원에서 범주형과 범주형에 대한 경우의 두 변수간 관계를 설명하겠습니다. 예를 들어 한 학생으로부터 얻어진 키와 몸무게 데이터가 paired data가 될 수 있습니다. paired data는 보통 다음과 같은 형태를 취하고 있습니다. \\[ (x_1, y_1), (x_2, y_2), ..., (x_{252}, y_{252}) \\] 걸리버 여행기라는 (1726) 소설이 나올 무렵의 사람들은 손목과 목, 허리 둘래가 항상 일정 비율로 비례하는 것을 알고 있었는데 이를 Lilliputians’ hypothesis라고 합니다. 이를 fat 데이터를 통해 알아 봅니다. UsingR 패키지의 fat 데이터는 252명의 남성으로부터 얻어진 다른 신체 부위의 측정 값을 제공하고 있으며 fat index를 예측하기 위한 목적으로 사용될 수 있습니다. 본 강의에서는 neck과 wrist 두 변수간의 관계를 설명하기 위한 데이터로 사용됩니다. library(UsingR) class(fat) head(fat) names(fat) neck_pair &lt;- fat$neck wrist_pair &lt;- fat$wrist mean(neck_pair/wrist_pair) mean(neck_pair)/mean(wrist_pair) plot(neck_pair, wrist_pair) 손목과 목 둘레를 측정한 데이터의 대표값 (평군)을 이용하여 두 변수 사이의 비율을 계산해 보면 2.084로 거의 두 배의 비율을 보입니다. 짝 데이터가 아닌 경우의 비율은 어떻게 될지 계산해 보면 아래와 같이 2.08로 비슷한 값이 구해집니다. 그러나 plot을 사용해서 산점도를 그려보면 nopair 데이터의 경우 두 변수의 상관성이 사라지는 것을 알 수 있습니다. neck_nopair &lt;-sample(fat$neck) wrist_nopair &lt;- sample(fat$wrist) mean(neck_nopair)/mean(wrist_nopair) mean(neck_nopair/wrist_nopair) plot(neck_nopair, wrist_nopair) 4.3.1 Pearson Correlation 상관 또는 상관계수는 두 변수의 선형적 관계를 정량적으로 나타내는 척도입니다. 상관계수의 값이 0일 경우 두 변수는 독립 (independence)이라고 할 수 있고 선형 관계에 대해서만 사용됩니다. x &lt;- fat$wrist y &lt;- fat$neck plot(x, y) abline(v = mean(x), lty=2) abline(h = mean(y), lty=2) points(mean(x), mean(y), pch=16, cex=4, col=&quot;#00000055&quot;) abline(lm(y~x)) 공분산 (covariance)와 상관 (correlation)은 데이터의 중앙을 기준으로 4개의 구역에 각 데이터가 흩어진 정도를 정량화 한 것이며 다음과 같이 정의됩니다. \\[ cov(x, y) = \\frac{1}{n-1} \\sum{(x_i-\\bar{x})(y_i-\\bar{y})} \\] \\[ cor(x, y) = \\frac{1}{n-1} \\sum{(\\frac{x_i-\\bar{x}}{s_x})(\\frac{y_i-\\bar{y}}{s_y})} = cov(x,y)/(s_x s_y)\\] cor(fat$wrist, fat$neck) cor(fat$wrist, fat$height) cor(fat$age, fat$ankle) 4.3.2 Spearman correlation coefficient 피어슨 상관계수는 선형적 관계에 대한 정량화만 가능한 반면 spearman 상관계수는 선형관계 뿐만 아니라 비선형 적인 관계에 대해서도 단조 증가나 감소에 대한 정보를 측정할 수 있는 measure 입니다. 이는 데이터의 값 자체를 사용하기 보다는 데이터를 rank 값으로 변환한 후 상관성을 비교하기 때문에 가능한 기능입니다. from wiki x &lt;- Animals$body y &lt;- Animals$brain cor(x, y) plot(x, y) Animals cor(rank(x), rank(y)) cor(x, y, method=&quot;spearman&quot;) Animals 데이터에서 correlation 값이 낮은 이유는 공룡과 같이 뇌 무게에 비해 비정상적으로 큰 몸무게 값을 갖는 개체들 때문입니다. Example: 공룡을 제외한 correlation을 구하시오 일반적으로 분석의 신뢰성을 높이기 위해 실험 반복을 통해 데이터를 수집합니다. 그런데 가끔은 전체 반복 데이터를 모두 사용해서 상관계수를 구하는 값보다 각 반복 데이터의 평균에 대한 상관 계수를 구랗 때 더 높은 상관 관계를 확인할 수 있습니다. ToothGrowth plot(ToothGrowth$dose, ToothGrowth$len) cor(ToothGrowth$dose, ToothGrowth$len) l &lt;- split(ToothGrowth$len, ToothGrowth$dose) group_means &lt;- c(mean(l[[1]]), mean(l[[2]]), mean(l[[3]])) points(c(0.5, 1, 2), group_means, col=&quot;red&quot;, pch=17, cex=2) cor(c(0.5, 1, 2), group_means) 4.3.3 Correlation, causation and association 상관성 분석 중 유의할 점 중 하나는 상관성이 인과 관계를 의미하지 않는 다는 점 입니다. Smoking vs. cancer (1950) 연구의 경우 폐암 발병의 원인으로 담배에 대한 입장이 Industry 입장에서의 견해와 health care researchers 입장에서 견해가 다를 수 있습니다. Lurking variables 또는 compounding effect라고 불리우는 효과는 원인과 결과가 되는 두 요소에 모두 상관성을 갖는 변수로서 당시 담배가 폐암에 원인인지 아닌지에 대한 논란을 일으켰습니다. Simpson’s paradox 현상은 전체 데이터의 상관성이 하위 그룹별로 고려한 상관성과 반대가 되는 경우를 말합니다. cor(SAT$salary, SAT$total) plot(salary~total, data=SAT, cex=2) points(salary~total, SAT, subset = perc &lt; 10, col=&quot;red&quot;, pch=15, cex=2) points(salary~total, SAT, subset = perc &gt; 40, col=&quot;blue&quot;, pch=16, cex=2) abline(lm(SAT$salary~SAT$total)) abline(lm(salary~total, SAT, subset = perc &lt; 10), col=&quot;red&quot;) abline(lm(salary~total, SAT, subset = perc &gt; 40), col=&quot;blue&quot;) 반응변수 y와 설명변수 x의 관계는 다음 그림과 같은 경우의 수를 생각할 수 있습니다. UsingR 직접적 원인에 의한 결과를 설명하는 인과관계로 설명이 어렬울 경우 좀 더 넓은 범위의 연관성(Association) 으로 두 변수가 관련이 있음을 표현하는 것도 하나의 방법입니다. 1996년 오스트레일리아의 총기 소유자들에게 총기를 다시 사들이는 정부 정책과 자살율에 관한 연구가 그 예제 입니다. 4.3.4 Trends 앞서 상관계수는 두 (연속형) 변수간의 관계를 나타내는 척도라고 설명을 했습니다. 하나의 변수는 연속형이고 다른 변수가 범주형 변수일 경우에도 각 범주형 변수의 그룹이 값는 평균값을 비교하여 관계를 유추할 수 있습니다. 즉, 각 그룹의 평균값들을 선으로 연결하였을 때 그 기울기가 일정하면 그룹의 변화에 따른 반응값이 선형적으로 일정한 관계에 있다고 해석할 수 있습니다. 선형적 트렌드는 다음과 같은 모형으로 나타낼 수 있습니다. \\[ \\mu_{y|x} = \\beta_0 + \\beta_1 x \\] 여기서 \\(\\mu_{y|x}\\) 는 설명변수 \\(x\\) 가 주어진 상태에서 반응변수의 평균으로 볼 수 있습니다. 각 데이터포인트의 경우 \\[y_i = \\beta_0 + \\beta_1 x_i + e_i\\] 이며 \\(e_i\\)는 에러를 나타냅니다. \\(\\beta\\) 값들은 계산을 해야 알 수 있지만 0일 경우 \\(y\\) 값은 항상 일정하고 에러의 평균은 0이 됨을 가정하고 있습니다. 이제 \\(\\beta\\)가 0인지 아닌지를 계산하면 두 변수가 연관이 있는지에 대한 판단을 할 수 있습니다. \\(\\beta\\)를 구하기 전에 우선 error, residual, 그리고 bias 에 대한 념을 정확히 알아두는 것이 좋습니다. 4.3.5 The method of least squares 정의에 의해서 잔차는 다음과 같습니다. 즉 잔차는 관측값에서 추정된값과의 차이입니다. \\[ \\hat{y}_i = b_0 + b_1 x_i \\] \\[ residual = y_i - \\hat{y}_i \\] \\(\\beta\\) 값은 최소제곱추정법이라는 방법으로 구할 수 있는데 이 방법은 각 점에서의 잔차를 최소화 하는 선분을 (회귀선) 구하는 과정이며 \\(\\beta\\)는 해당 선분의 기울기로 볼 수 있습니다. 즉, 추정에 의해서 구해진 회귀선은 squared residual을 최소화 하는 선분이라고 해석할 수 있습니다. 선분 \\(\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\\)의 최소 제곱법에 의한 \\(\\beta_0\\)와 \\(\\beta_1\\)의 추정값 \\(\\hat{\\beta}_0\\)와 \\(\\hat{\\beta}_1\\)은 다음과 같이 정의 됩니다. \\[ \\hat{\\beta}_1 = \\frac{\\sum(x_i - \\bar{x})(y_i-\\bar{y})}{\\sum(x_i - \\bar{x})^2} = cor(x,y)\\frac{s_y}{s_x}\\] \\[ \\hat{\\beta}_0 = \\hat{y} - \\hat{\\beta}_1 x \\] 위 두 식에서 회귀선분의 기울기인 \\(\\hat{\\beta}_1\\)은 상관계수에 \\(s_y / s_x\\)를 곱한 수로 1만큼 x 축으로 변할 때 변화하는 y 값의 평균 변화량으로 해석하면 되겠습니다. 또한 상관계수와는 달리 설명변수와 반응변수인 \\(x\\)와 \\(y\\)가 바뀔경우 값이 달라지며 여전히 잔차의 합은 0가 됩니다. R에서는 다음과 같이 lm 함수를 사용하며 이 함수에 대한 더 자세한 내용은 11장에서 다시 배우게 되겠습니다. ?lm out &lt;- lm(maxrate ~ age, data=heartrate) out ## visualize fitted line names(out) summary(out) plot(maxrate ~ age, data=heartrate) abline(out) ## residuals sum(resid(out)) sum(out$residuals) res &lt;- heartrate$maxrate - out$fitted.values sum(res) ## fitted values age &lt;- c(30, 40) out$coefficients[1] + out$coefficients[2]*age predict(out, data.frame(age)) head(heartrate) predict(out, data.frame(age=30)) Example: fit 데이터에서 abdomen 과 wrist의 산점도를 그리고 선형모형을 적합한 후 추세선을 그리시오. 17cm wrist 크기를 갖는 사람은 얼마의 abdomen의 값을 가질지 예측하시오. correlation vs. association vs. relation https://stats.stackexchange.com/questions/371747/association-relationship-and-correlation 4.4 Bivariate categorical data 이번 단원에서는 두 종류의 짝데이터가 모두 범주형일 경우에 그 연관성을 정량화하는 방법에 대해서 알아보겠습니다. 4.4.1 Contingency tables 일반적으로 범주형 데이터는 각 샘플의 그룹 정보를 표시하여 나타내며 분석을 위해서는 이러한 그룹 정보를 기준으로 각 그룹에 해당하는 샘플의 갯수를 카운팅하여 contingency table로 변환하여 분석을 수행하게 됩니다. 두 범주형 변수의 경우는 two-way contingency table로 나타낼 수 있습니다. R에서는 다음과 같은 다양한 방법으로 테이블을 만듭니다. rbind(c(56,8), c(2,16)) cbind(c(56,2), c(8,16)) seatbelts &lt;- matrix(c(56, 2, 8, 16), nrow=2) rownames(seatbelts) &lt;- c(&quot;buckled&quot;,&quot;unbuckled&quot;) colnames(seatbelts) &lt;- c(&quot;buckled&quot;,&quot;unbuckled&quot;) seatbelts rownames(seatbelts) &lt;- c(&quot;pa_buckled&quot;,&quot;pa_unbuckled&quot;) colnames(seatbelts) &lt;- c(&quot;ch_buckled&quot;,&quot;ch_unbuckled&quot;) seatbelts dimnames(seatbelts) &lt;- list(parent=c(&quot;buckled&quot;,&quot;unbuckled&quot;), child=c(&quot;buckled&quot;,&quot;unbuckled&quot;)) seatbelts head(grades) str(grades) mytbl &lt;- table(grades$prev, grades$grade) 4.4.2 Marginal distributions 연관성을 정량화 하기 전에 알아야할 두 가지 개념 중 하나는 주변분포 (marginal distribution)이고 다른 하나는 조건부분포 (conditional distributoin) 입니다. two-way 테이블은 두 개의 변수에 대한 요약 정보를 나타내며 각 변수들의 분표를 독립적으로 정량화 한 경우를 주변분포라고 합니다. R에서는 colSums, rowSums 또는 margin.table을 이용하여 계산 할 수 있습니다. mytbl rowSums(mytbl) margin.table(mytbl, margin=1) colSums(mytbl) margin.table(mytbl, margin=2) 4.4.3 Conditional distributions 조건부 분포는 위 분할표 (contingency table)의 하나의 row에 대해서 다른 row와 비교하는 경우를 생각하면 됩니다. 즉 위 안전벨트 데이터에서 부모가 벨트를 맬 경우와 매지 않을 경우 각각에 대한 아이들의 벨트 착용 비율을 말합니다. \\[ p(C=b|P=b) = \\frac{p(C=b, P=b)}{p(P=b)} \\] R에서는 Marginal 분포 값으로 각 해당하는 cell의 값을 나누어 비율을 계산할 수 있습니다. Seatbelt 데이터의 경우 부모가 벨트를 착용할 경우 아이들이 착용하는 비율이 0.875이고 부모가 착용하지 않을 때 아이들이 착용하는 비율은 0.11로 차이가 보임을 알 수 있습니다. prop.table(seatbelts) seatbelts/sum(seatbelts) prop.table(seatbelts, margin=1) prop.table(seatbelts, margin=2) R 이 제공하는 xtabs 함수를 사용하면 위와 같은 계산을 쉽게 할 수 있습니다. 다음 Fingerprints 데이터는 whorls 와 Loops의 갯수의 조합에 해당하는 사람들의 수를 세어놓은 데이터입니다. NA를 제외하고 테이블을 만들기 위해서는 각 카테고리별로 테이블을 나누고 해당 cell에 맞는 값을 할당하는 복잡한 과정이 필요하지만 xtabs 함수를 사용하면 위 과정을 쉽게 수행할 수 있습니다. head(Fingerprints) tail(Fingerprints) ## without xtabs idx &lt;- !is.na(Fingerprints$count) Fingerprints[idx,] whorls &lt;- rep(Fingerprints$Whorls[idx], Fingerprints$count[idx]) loops &lt;- rep(Fingerprints$Loops[idx], Fingerprints$count[idx]) table(whorls, loops) ## with xtabs xtabs(count ~ Whorls + Loops, Fingerprints) xtabs(count ~ ., Fingerprints) 4.4.4 Graphical summaries of contingency tables 테이블 데이터를 가시화 하는 가장 쉬운 방법은 barplot 함수를 이용하는 것 입니다. barplot(seatbelts) barplot(seatbelts, beside=T) barplot(seatbelts, beside=T, legend=rownames(seatbelts)) barplot(seatbelts, beside=T, legend=rownames(seatbelts), col=c(&quot;red&quot;, &quot;blue&quot;)) mosaic plot은 barplot을 확장한 개념이나 실제 많이 쓰이진 않습니다. titanic 예제는 타이타닉호에 탑승했던 승객들의 객실 등급과 생존 유무 등을 정리해 놓은 데이터셋 입니다. mosaic plot을 통해서 Sex와 Survived 의 관계를 관측할 수 있으며 이를 확장하여 Class에 대한 분류를 더 하여 정보를 비교할 수 있습니다. titanic &lt;- as.data.frame(Titanic) head(titanic) xtabs(Freq ~ Survived + Class, data=titanic, subset=Sex==&quot;Female&quot;) xtabs(Freq ~ Survived + Class, data=titanic) xtabs(Freq ~ Sex, titanic) tbl &lt;- xtabs(Freq ~ Sex + Survived, titanic) mosaicplot(tbl) tbl &lt;- xtabs(Freq ~ Sex + Survived + Class, titanic) mosaicplot(tbl) 4.4.5 Measures of association for categorical data 타이타닉 데이터에서 객실 등급과 생존율의 그룹별 사람수를 보면 다음과 같이 등급별로 생존 비율이 크게 다른 패턴을 가짐을 알 수 있습니다. 이는 두 변수가 서로 상관되어 있음을 의미하는데 비록 이 변수들이 숫자형 변수는 아니지만 자연스럽게 그룹별로 정렬될 수 있고 따라서 그룹별 비율을 비교하므로써 상관성에 대한 유무를 판단할 수 있습니다. mosaicplot(xtabs(Freq ~ Class + Survived, data=titanic)) Kendal tau correlation은 concordant/discordant pair를 이용한 정량적 연관성 측정값으로 다음과 같이 계산 할 수 있습니다. 특정 관측 데이터 pair (x1, y1)과 (x2, y2)가 있을 때 x1과 y1이 x2, y2에 비해서 둘 다 높은 (또는 낮은) rank에 위치할 경우 concordant 하다고 하며 반대로 x2 또는 y2 둘 중 하나는 높으나 다른 하나는 낮은 또는 그 반대인 경우 discordant 한 것으로 정의 됩니다. 피어슨 상관성과 같은 -1부터 1사이의 값을 가지며 0은 연관이 전혀 없는 경우를 말합니다. \\[ \\tau = \\frac{Number ~ of ~ concordant ~ pair - Number ~ of ~ discordant ~ pair}{n(n-1)/2} \\] The chi-squared statistics 는 가장 널리 쓰이는 범주형 자료의 연관성 척도로 다음과 같이 정의됩니다. 수식의 “o”와 “e”는 각각 관측값과 예측값을 나타냅니다. 이 값이 클 경우 연관이 크다는 것이고 크고 작음에 대한 검증은 10장에서 다시 다루기로 합니다. \\[ chi-squared ~ statistic = \\sum \\frac{(f_o - f_e)^2}{f_e} \\] Example. 다음 seatbelt 데이터에서 괄호를 채우시오. hint: 만약 부모와 아이들의 안전벨트를 매는 두 사건 (변수)가 독립이라면 \\(p(C, P) == p(C)p(P)\\) 즉, 결합확률이 각 확률을 곱한 것과 같고 기대값은 확률 x 전체 사건의 수(\\(N\\)) 이므로 다시 적으면 \\(N p(C,P) == N p(C)p(P)\\)임. 여기서 \\(N p(C,P)\\)는 우리가 관측한 값으로 볼 수 있고 \\(N p(C) p(P)\\)는 독립을 가정한 상태에서 기대값이라고 볼 수 있음. fo &lt;- tbl fo ## marginal probability margin_rows &lt;- rowSums(fo)/sum(fo) margin_cols &lt;- colSums(fo)/sum(fo) ## expected numbers sum(fo)*margin_rows[?]*margin_cols[?] sum(fo)*margin_rows[?]*margin_cols[?] sum(fo)*margin_rows[?]*margin_cols[?] sum(fo)*margin_rows[?]*margin_cols[?] ## use chisq.test function fe &lt;- chisq.test(tbl)$expected (fo-fe)^2 / fe sum((fo-fe)^2 / fe) 4.5 Homeworks 각 문제의 풀이는 R 코드와 같이 haseong@kribb.re.kr 로 다음 강의시간 전까지 보내주시면 되겠습니다. 4.5.1 HW3-1 다음 데이터를 age 변수에 저장하고 mean, median, variance 를 구하시오 {7, 9, 2, 64, 41, 60, 82, 31, 38, 25, 52, 68, 67} 위 age 데이터를 z-score로 변환 하고 zage 변수에 저장하시오 age와 zage 두 데이터셋에 대한 각각의 boxplot을 그리고 중간값을 출력하시오 age &lt;- c(7, 9, 2, 64, 41, 60, 82, 31, 38, 25, 52, 68, 67) mean(age) median(age) var(age) zage &lt;- (age-mean(age))/sd(age) zage median(age) median(zage) boxplot(data.frame(age, zage)) text(1, 50, median(age)) text(2, 50, round(median(zage),3)) 4.5.2 HW3-2 UScereal 데이터셋은 미국 식료품점의 선반에 진열된 시리얼 제품의 정보에 대한 데이터임. 시리얼 생산 브랜드와 (UScereal\\(mfr) 디스플레이되는 floor 층 수 (UScereal\\)shelf) 관계를 나타내는 테이블을 구해서 tbl 변수에 저장하고 출력하시오 library(MASS) head(UScereal) str(UScereal) ?UScereal UScereal$mfr 브랜드와 진열 층 수와의 관계를 barplot으로 표현하시오 테이블의 각 cell 별 기대값을 구하고 chisqure 값을 구하시오 tbl &lt;- as.matrix(table(UScereal$mfr, UScereal$shelf)) barplot(tbl, beside=T) colvals &lt;- colSums(tbl)/sum(tbl) rowvals &lt;- rowSums(tbl)/sum(tbl) fl1_exp &lt;- rowvals * colvals[1] * sum(tbl) fl2_exp &lt;- rowvals * colvals[2] * sum(tbl) fl3_exp &lt;- rowvals * colvals[3] * sum(tbl) tbl_exp &lt;- data.frame(fl1_exp, fl2_exp, fl3_exp) chisq_val &lt;- sum(((tbl-tbl_exp)^2)/tbl_exp) chsq &lt;- chisq.test(tbl) c(computed=chisq_val, chsq$statistic) "],
["multivariate-data.html", "Chapter 5 Multivariate data 5.1 Introduction 5.2 Data structures in R 5.3 Working with data frame I 5.4 working with data frame II 5.5 Multivariate graphics - ggplot2 package", " Chapter 5 Multivariate data 5.1 Introduction 앞서 장에서는 기본적인 변수에 대한 대표값들과 두 개 이상의 변수가 주어졌을 경우 그 관계를 정량화 하는 과정을 학습했습니다. 그러나 일반적인 데이터 분석은 두 개 이상의 변수와 샘플들에 대해서 정제, 변환, 가시화, 대표값 비교 및 모델링으로 이어지는 단계로 이루어질 수 있습니다. 본 장에서는 R을 사용해서 위 데이터 분석 과정을 수행하기 위해 필요한 프로그래밍 기술을 습득하기 위해 최근 대표적으로 사용되는 apply 함수들과 dplyr 패키지 사용에 대한 학습을 목표로 합니다. 5.2 Data structures in R 5.2.1 Vectors 같은 타입의 데이터를 (Numeric, character, factor, …) 모아 놓은 컨테이너로서 인덱스는 [, ]를 사용합니다. 5.2.2 Lists 앞 장에서 학습한 것처럼 list 변수 타입은 vector 형태의 여러개의 element를 가질 수 있으며 각 element의 데이터는 문자나 숫자 어떤 데이터 타입도 가능하며 각 element vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 [ ]는 리스트를 반환하고 [[ ]]는 vector element들을 반환합니다. 5.2.3 Matrices 메트릭스는 같은 타입의 데이터로 채워진 사각형 모양을 갖는 컨테이너로 볼 수 있습니다. 인덱스는 [i, j] 형태로 i는 row, j는 column 을 가리킵니다. 메트릭스의 생성은 matrix 명령어를 사용하며 다음과 같이 각 column 별로 값을 채워 나가는 것이 기본 설정이며 byrow=T 를 통해 row를 다 채우고 그 다음 row를 채워 나가게 할 수도 있습니다. m &lt;- matrix(c(1,2,3,4), nrow=2) m m &lt;- matrix(c(1,2,3,4), nrow=2, byrow = T) m row와 column 이름은 rownames와 colnames로 설정이 가능하며 rbind와 cbind는 벡터를 연결하고 붙이는 역할을 할 수 있으나 데이터가 많거나 반복해서 수행할 경우 컴퓨터의 리소스를 많이 사용하는 문제로 느려질 수 있습니다. m &lt;- cbind(1:3, c(1.1, 1.2, 1.3), c(1, 1, 2)) # a 3 by 3 matrix colnames(m) &lt;- c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;) # or cbind(x=..., ...) m dim(m) 5.2.4 data.frame data frame은 변수들의 집합으로 list형과 비슷하지만 각 변수 element들이 똑같은 길이를 가지고 matrix 형태로 표현되는 것이 다릅니다. 변수들의 이름을 이용하여 $ 기호로 각 변수들의 데이터에 접근 할 수 있고 matrix와 같이 [i,j] 형태의 인덱싱도 가능합니다. 5.3 Working with data frame I 앞서 잠깐 소개한 것과같이 일반적인 데이터 분석은 데이터 클리닝, 변환, 가시화, 대표값비교, 모델링의 반복적인 수행으로 진행될 수 있습니다. 특히 R에서는 data frame 타입의 데이터로 대부분의 분석이 진행되므로 data frame 기반의 다양한 기법을 익혀야 합니다. 5.3.1 some exercises EXERCISE state.x77 데이터셋에서 population과 Life Exp, 그리고 Murder 변수만을 이용한 새로운 matrix를 만드시오. str(state.x77) newstate &lt;- state.x77[,c(1,4,5)] class(newstate) str(newstate) EXERCISE 위 matrix에 각 주의 이름을 값으로 갖는 새로운 변수 state_name을 추가해 보시오 rownames(state.x77) head(state.x77) state_names &lt;- rownames(state.x77) newstate &lt;- data.frame(state_names, state.x77[,c(1,4,5)]) head(newstate) str(newstate) newstate &lt;- data.frame(state_names, state.x77[,c(1,4,5)], stringsAsFactors = F) str(newstate) EXERCISE newstate data frame의 population과 Life Exp, Murder 변수들의 분포를 boxplot을 이용하여 비교하고 표준화 후 분포가 어떻게 변하는지 설명하시오 boxplot(newstate[,-1]) newstate$popstd &lt;- (newstate$Population - mean(newstate$Population))/sd(newstate$Population) newstate$lifexpstd &lt;- (newstate$Life.Exp - mean(newstate$Life.Exp))/sd(newstate$Life.Exp) newstate$murderstd &lt;- (newstate$Murder - mean(newstate$Murder))/sd(newstate$Murder) boxplot(newstate$popstd, newstate$lifexpstd, newstate$murderstd) boxplot(data.frame(newstate$popstd, newstate$lifexpstd, newstate$murderstd)) ## one vector, No use &quot;c&quot; boxplot(c(newstate$popstd, newstate$lifexpstd, newstate$murderstd)) EXERCISE 세 변수간 상관계수를 구하고 관계를 그래프로 나타내시오. cor(newstate$Population, newstate$Life.Exp) cor(newstate$Population, newstate$Murder) cor(newstate$Life.Exp, newstate$Murder) plot(newstate$Population, newstate$Life.Exp) plot(newstate$Population, newstate$Murder) plot(newstate$Life.Exp, newstate$Murder) 5.3.2 subset and filter subset함수를 이용하면 비교적 쉽게 원하는 조건을 갖는 subset 데이터를 만들 수 있습니다. filter 함수도 비슷한 기능을 수행합니다. d &lt;- airquality[1:10,] ## subset d ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 위 데이터셋에서 NA를 제외한 나머지 데이터만으로 새로운 데이터셋을 만들어 봅시다. is.na함수를 사용하면 해당 데이터가 NA인지 TRUE 또는 FALSE 를 반환해 줍니다. d[c(T,F,T,T),] d ds &lt;- d[!is.na(d[,1]),] ds &lt;- ds[!is.na(ds[,2]),] ds &lt;- d[!is.na(d[,1]) &amp; !is.na(d[,2]),] ds &lt;- subset(d, (!is.na(d$Ozone) &amp; !is.na(d$Solar.R))) ds &lt;- subset(d, complete.cases(d)) ds2 &lt;- filter(d, (!is.na(d$Ozone) &amp; !is.na(d$Solar.R))) ds2 &lt;- filter(d, complete.cases(d)) EXERCISE subset을 사용해서 Temp와 Month 변수만을 선택 후 새로운 data.frame ds3를 만드세요 head(d) d[,c(4,5)] d[,c(&quot;Temp&quot;, &quot;Month&quot;)] subset(d, select=c(&quot;Temp&quot;, &quot;Month&quot;)) 5.3.3 transforming 대부분의 R에서 제공하는 함수는 argument로 전달되는 값에 의해 데이터가 바뀌지 않는 pure function 입니다. 그러나 argument에 의해서 데이터를 바꿀 수 있다면 편리한 경우가 있습니다. 다음 예처럼 with 또는 within 함수를 사용하면 argument로 전달되는 데이터가 변형되어 반환될 수 있습니다. d &lt;- airquality d d$Hr &lt;- d$Day*24 with(d, {Day&lt;10}) d2 &lt;- within(d, {Hr2=Day*24}) #d3 &lt;- transform(d2, {Hr4 = Day*24}) #d3 EXERCISE d2 dataframe에서 Month를 day로 바꾸고 이를 다시 시간으로 바꾼 후 Hr2와 더한 새로운 Hr3 변수를 추가한 데이터프레임을 만드세요 head(d2) d3 &lt;- within(d2, { Hr3 &lt;- Month*30*24 + Day*24 }) head(d3) 5.3.4 reshaping 보통의 matrix나 data frame 형식의 raw 데이터는 샘플이 row에 나오고 column에는 변수가 위치하는 wide 형식의 데이터라고 볼 수 있습니다. 즉, 변수가 증가할 때 마다 wide하게 넓어지는 형식이고 그러나 R 기반의 데이터분석이나 모델링을 위해서는 필요에 따라 long 형식의 데이터로 변환할 필요가 있습니다. 이럴 때 주로 사용하는 함수는 reshape 함수나 reshape2 패키지의 melt 함수 입니다. 먼저 reshape 함수의 사용법을 알아 봅니다. reshape의 파라메터 중 direction=“wide” 이고 varying 또는 v.names 가 주어지지 않은 경우 idvar나 timevar에 명시된 변수를 제외하고 모두 시간에 따라 변하는 관측된 값이 됩니다. 아래 경우 Expt에 주어진 변수의 값들이 시간에 따라 변하는 값들을 갖는 관측 변수 이름으로 주어지고 idvar에 명시된 변수의 값들은 각 시간별로 관측된 데이터의 id가 됩니다. #library(reshape2) morley #long speed_wide &lt;- reshape(morley, idvar = &quot;Run&quot;, timevar=&quot;Expt&quot;, direction=&quot;wide&quot;) speed_wide 이제 위 wide형 데이터를 long형 데이터로 바꿔보겠습니다. reshape(speed_wide, idvar = &quot;Run&quot;, direction = &quot;long&quot;) #wide df &lt;- data.frame(id = rep(1:4, rep(2,4)), visit = I(rep(c(&quot;Before&quot;,&quot;After&quot;), 4)), x = rnorm(4), y = runif(4)) df reshape(df, timevar = &quot;visit&quot;, idvar = &quot;id&quot;, direction = &quot;wide&quot;) #long df3 &lt;- data.frame(id = 1:4, age = c(40,50,60,50), dose1 = c(1,2,1,2), dose2 = c(2,1,2,1), dose4 = c(3,3,3,3)) df3 df4 &lt;- reshape(df3, direction = &quot;long&quot;, varying = 3:5, sep = &quot;&quot;) head(df4) summary(lm(age~dose, df4)) 5.3.5 merging data merge 함수는 두 개 이상의 데이터셋을 통합하는 기능을 수행하는 함수입니다. 이 외에도 dplyr 패키지의 inner_join 함수도 많이 쓰이나 이는 이 후 dplyr 패키지 사용에 대한 내용을 배울 예정입니다. EXERCISE 산모의 흡연 여부와 신생아 몸무게의 관계를 알아보는 데이터 분석입니다. UsingR 패키지의 babies 데이터셋에서 missing 값들에 대한 NA 처리 후 smoke 변수를 factor 형으로 변환한 데이터셋을 만들어 봅니다. 각 변수당 하나씩 처리를 해보고 within 함수도 사용해 보겠습니다 . library(UsingR) head(babies) plot(babies$gestation) babies$gestation[babies$gestation&gt;900] &lt;- NA 직관적으로 위와 같이 수행할 수 있으나 babies$ 를 반복해서 입력해주는 불편함이 있습니다. b &lt;- within(babies, { gestation[gestation==999] &lt;- NA wt[wt == 999] &lt;- NA }) head(b) str(b) 또한 smoke 변수는 흡연 여부를 나타내는 범주형 변수로 0, 1, 2, 3 값은 의미가 없습니다. 사람이 읽을 수 있는 label을 붙인 factor 형 변수로 변환하겠습니다. babies$smoke b2 &lt;- within(b, { smoke = factor(smoke) levels(smoke) = list( &quot;never&quot; = 0, &quot;smoke now&quot; = 1, &quot;until current pregnancy&quot; = 2, &quot;once did, not now&quot; = 3) }) head(b2) 본격적인 통계 분석을 아직 배우진 않았으나 처음 가설에 대한 간단한 결과를 보면 현재 흡연중인 산모는 임신기간과 신생아 몸무게와 음의 상관 관계가 있음을 알 수 있습니다. dim(b2) fit &lt;- lm(gestation~smoke, b2) summary(fit) boxplot(gestation~smoke, b2, ylim=c(250, 300)) fit &lt;- lm(wt~smoke, b2) summary(fit) boxplot(wt~smoke, b2) 이제 smoke now 인 경우 또는 나이가 25세 미만인 경우의 샘플에 대해서 subdata를 만들어 봅니다 (subset 함수 사용, id, gestation, age, wt, smok 변수만 사용). 또한 이렇게 만들어진 두 데이터셋을 merge 함수를 이용해서 하나의 데이터셋으로 만들어 봅니다. ## merge b3 &lt;- subset(b2, {smoke==&quot;smoke now&quot;}, c(id, gestation, age, wt, smoke)) b4 &lt;- subset(b2, {age&lt;25}, c(id, gestation, age, wt, smoke)) head(b3) head(b4) b.in &lt;- merge(b3, b4, by.x=&quot;id&quot;, by.y=&quot;id&quot;, all=FALSE) b.out &lt;- merge(b3, b4, by.x=&quot;id&quot;, by.y=&quot;id&quot;, all=TRUE) 5.3.6 split split 함수는 데이터 벡터를 주어진 factor 형 값으로 나누는 기능을 하는 함수 입니다. g &lt;- airquality$Month head(airquality) dim(airquality) table(g) l &lt;- split(airquality, g) length(l) boxplot(l[[1]]$Ozone) EXERCISE airquality 데이터의 Month에 따른 Ozone 의 분포를 boxplot을 이용해서 비교하시오. (subset??)을 이용하여 Month에 따른 각각의 Ozone의 값들로 새로운 변수들 v5, v6, v7, v8, v9을 만들고 이들을 하나의 data frame으로 만드시오 head(airquality) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 boxplot(formula=Ozone~Month, data=airquality) boxplot(airquality$Ozone~airquality$Month) EXERCISE 가장 직관적으로 먼저 필요한 기능을 하나의 데이터 엘리먼트에 대해서 수행하는 스크립트를 먼저 작성해 보고 필요한 index를 붙이거나 for 문을 활용해서 원하는 형태의 데이터 변환을 완료하시오 oz &lt;- data.frame(airquality$Ozone[airquality$Month==5], airquality$Ozone[airquality$Month==6], airquality$Ozone[airquality$Month==7], airquality$Ozone[airquality$Month==8], airquality$Ozone[airquality$Month==9]) oz &lt;- list(airquality$Ozone[airquality$Month==5], airquality$Ozone[airquality$Month==6], airquality$Ozone[airquality$Month==7], airquality$Ozone[airquality$Month==8], airquality$Ozone[airquality$Month==9]) boxplot(oz) ## soz &lt;- list() soz[[1]] &lt;- (oz[[1]]-mean(oz[[1]], na.rm=T))/sd(oz[[1]], na.rm=T) soz[[2]] &lt;- (oz[[2]]-mean(oz[[2]], na.rm=T))/sd(oz[[2]], na.rm=T) soz[[3]] &lt;- (oz[[3]]-mean(oz[[3]], na.rm=T))/sd(oz[[3]], na.rm=T) soz[[4]] &lt;- (oz[[4]]-mean(oz[[4]], na.rm=T))/sd(oz[[4]], na.rm=T) soz[[5]] &lt;- (oz[[5]]-mean(oz[[5]], na.rm=T))/sd(oz[[5]], na.rm=T) soz boxplot(soz) soz &lt;- list() for(i in 1:5){ soz[[i]] &lt;- (oz[[i]]-mean(oz[[i]], na.rm=T))/sd(oz[[i]], na.rm=T) } boxplot(soz) 반복적으로 수행하는 일들은 apply 계열 함수를 사용하면 쉽게 기능을 수행할 수 있습니다. l1 &lt;- transform(l[[1]], ozz=scale(Ozone)) l1 l2 &lt;- transform(l[[2]], ozz=scale(Ozone)) l2 soz2 &lt;- lapply(l, function(x){scale(x$Ozone)}) boxplot(soz2) 5.4 working with data frame II 앞서 배운 일련의 작업들은 R에서 기본적으로 제공되는 함수를 사용한 경우입니다. 이 외에 R이 갖는 장점인 행렬, 벡터연산 기능을 최대한 활용할 수 있는 기능들에 대한 내용을 배워봅니다. dplyr, reshape2 등의 별도 패키지에대한 설치가 필요합니다. 5.4.1 apply 데이터를 다룰 때 각 원소별, 그룹별, row, column 별로 다뤄야 할 경우가 많으며 apply 계열의 합수는 이러한 기능을 제공하는 함수로써 적절히 사용하면 효율성이나 편리성 뿐만 아니라 코드의 간결성 등 장점이 많은 기능입니다. colMean 과 같은 함수는 column 또는 row 단위로 해당하는 모든 값들에 대해 연산을 수행해주는 함수로 colMean은 평균을 계산하는 함수이고 일반적으로는 다음과 같이 apply 함수와 mean 함수를 이용해서 같은 기능을 수행할 수 있습니다. 아래는 앞서 babies 데이터셋 clearning 된 b2 데이터에 이어서 수행되는 내용입니다. library(UsingR) b &lt;- within(babies, { gestation[gestation==999] &lt;- NA wt[wt == 999] &lt;- NA }) b2 &lt;- within(b, { smoke = factor(smoke) levels(smoke) = list( &quot;never&quot; = 0, &quot;smoke now&quot; = 1, &quot;until current pregnancy&quot; = 2, &quot;once did, not now&quot; = 3) }) b3 &lt;- b2[,c(&quot;gestation&quot;, &quot;wt&quot;, &quot;dwt&quot;)] colMeans(b3) colMeans(b3, na.rm=T) b4 &lt;- within(b3, dwt[dwt==999]&lt;-NA) apply는 다음과 같이 작동을 합니다. apply(b4, 1, mean) apply(b4, 2, mean) apply(b4, 2, mean, na.rm=T) apply(b4, 2, sd) apply(b4, 2, sd, na.rm=T) apply(b4, 2, function(x){ xmean &lt;- mean(x, na.rm=T) return(xmean) }) 임의의 함수를 만들어서 사용할 수도 있습니다. apply 함수를 사용할 경우 행렬이 커질수록 계산 시간도 빨라질 수 있습니다. n &lt;- 40 m &lt;- matrix(sample(1:100, n, replace=T), ncol=4) m mysd &lt;- function(x){ xmean &lt;- sum(x)/length(x) tmpdif &lt;- x-xmean xvar &lt;- sum(tmpdif^2)/(length(x)-1) xsd &lt;- sqrt(xvar) return(xsd) } mysd(m[1,]) apply(m, 1, mysd) apply(m, 1, sd) [EXERCISE] for 문과 mysd를 이용하여 위 행렬 m의 4개 컬럼에 대한 stadard deviation을 구하시오 mysd(m[,1]) mysd(m[,2]) mysd(m[,3]) mysd(m[,4]) sd_result &lt;- rep(NA, 4) for(i in 1:4){ sd_result[i] &lt;- mysd(m[,i]) } sd_result apply(m, 2, mysd) 5.4.2 map and apply function family apply 함수 외에도 sapply, lapply, mapply 등의 다양한 apply계열 함수가 쓰입니다. # map collection &lt;- c(4, 9, 16) Map(sqrt, collection) sqrt(collection) sapply(collection, sqrt) # lst &lt;- with(ToothGrowth, split(len, supp)) sapply(lst, mean) sapply(lst, median) Map(median, lst) median(lst) mean(lst) # mapply Map(min, c(1,4), c(2,3)) #simplification of output mapply(min, c(1,4), c(2,3)) sapply는 lapply와 유사하며 벡터, 리스트, 데이터프레임 등에 함수를 적용하고 그 결과를 벡터 또는 행렬로 반환합니다. x &lt;- c(1:10) sapply(x, function(x){2*x}) x*2 x &lt;- list(a=1:10, b=exp(-3:3), logic=c(T,T,F,T)) sapply(x, quantile) quantile(x$a) x &lt;- data.frame(a=1:7, b=exp(-3:3), logic=c(T,T,F,T,T,T,F)) sapply(x, class) x 5.4.3 dplyr - pipe operator dplyr은 테이블형 데이터를 다루기 위한 도구를 제공하는 매우 편리한 패키지 입니다. %&gt;% 파이프 오퍼레이터를 사용하여 여러 함수를 연속적으로 사용할 수 있으며 R의 장점 중 하나인 apply와 같은 행렬 연산 기능을 subset, split, group 와 같은 행렬 편집 기능과 더하여 만들어낸 도구라고 할 수 있습니다 (홈페이지: https://dplyr.tidyverse.org/) 파이프 오퍼레이터 %&gt;% 의 단축키는 Ctrl + Shift + m 입니다. 이 오퍼레이터는 %&gt;%의 왼쪽 코드의 결과를 출력으로 받아 오른쪽 코드의 입력 (첫번째 파라미터의 값)으로 받아들이는 작동을 합니다. 다음 예에서 보면 sin(pi) 와 같은 함수의 일반적인 사용법 대신 pi %&gt;% sin 처럼 사용해도 똑같은 결과를 보여줍니다. cos(sin(pi))와 같이 여러 합수를 중첩하여 사용할 경우에도 코드 디자인의 가독성이나 효율 측면에서 크게 향상된 방법을 제공해 줍니다. library(dplyr) pi %&gt;% sin sin(pi) pi %&gt;% sin %&gt;% cos cos(sin(pi)) 특히 %&gt;%는 이후 설명할 dplyr의 group_by, split, filter, summary 등의 행렬 편집/연산 함수를 빈번히 다양한 조합으로 쓰게되는 상황에서 더 큰 효과를 발휘할 수 있습니다. 그에 앞서 pipe 오퍼레이터의 예제를 좀 더 살펴보겠습니다. pipe operator의 왼쪽 구문의 결과가 오른쪽 구문의 입력으로 처리된다고 설명드렸지만 엄밀히 따지면 오른쪽 구문의 첫 번째 파라미터의 입력 값으로 처리되는 것 입니다. 즉, 함수에서 사용되는 파라미터가 여러개일 경우가 있으므로 기본적으로 %&gt;% 의 왼쪽 구문의 출력 값은 오른쪽 구문 (함수)의 첫 번째 인자의 입력값으로 들어가는 것 입니다. 이는 다음 예들을 통해서 명확히 알 수 있습니다. 먼저 paste함수는 그 파라미터로 ,로 구분되는 여러개의 입력 값을 가질 수 있습니다. 따라서 다음 코드는 x가 paste의 첫 번째 파라미터로 들어가게 되어 &quot;1a&quot;, &quot;2a&quot;, &quot;3a&quot;, &quot;4a&quot;, &quot;5a&quot; 로 a 앞에 x 값들이 붙어서 출력된 것을 알 수 있습니다. x &lt;- 1:5 x %&gt;% paste(&quot;a&quot;, sep=&quot;&quot;) 특정 데이터셋의 컬럼별 평균을 구하고 각 평균의 합을 구할 경우를 생각해 봅시다. R에서는 colMeans라는 특별한 함수를 제공하여 컬럼별로 평균을 계산해 줍니다. 그 후 sum 함수를 사용하여 최종 원하는 값을 얻을 수 있습니다. 이러한 코드를 %&gt;% 오퍼레이터를 사용한 경우의 코드와 비교해 볼 수 있습니다. x &lt;- data.frame(x=c(1:100), y=c(201:300)) sum(colMeans(x)) x &lt;- data.frame(x=c(1:100), y=c(201:300)) x %&gt;% colMeans %&gt;% sum 만약 두 번째 또는 다른 위치의 파라미터에 입력으로 왼쪽 구문의 출력을 받아들이고 싶을 경우는 place holer라는 . 을 사용하면 되겠습니다. round 함수는 두 개의 파라미터를 가지고 digits 값을 pipe operator로 넘겨주고 싶을 경우 아래와 같이 표현할 수 있습니다. 6 %&gt;% round(pi, digits=.) round(pi, digits=6) [EXERCISE] 다음 행렬 m의 컬럼별 표준편차를 앞서 만든 mysd 함수와 apply 함수를 사용하여 구하되 %&gt;% 를 사용하시오 5.4.4 dplyr - Important functions dplyr을 구성하는 중요한 함수는 다음 5가지가 있습니다. mutate() - 기존 데이터셋에 새로운 변수 추가 select() - 주어진 데이터에서 변수 선택 filter() - 특정 값을 기준으로 샘플 (case) 선택 summarise() - 대표값 계산 arrange() - 샘플들의 배열 변환 그리고 위 다섯개의 함수들과 결합해서 자주 사용되는 group_by() 함수가 있습니다. 특히 summarise 함수와 같이 사용될 때 강력한 성능을 발휘합니다. 여러개 함수를 동시에 적용할 때는 %&gt;%를 이용할 수 있으며 summarise 외 5개 함수들은 행렬 편집을 위한 함수들로 보시면 되겠습니다. 예제를 수행하면서 각각의 기능을 살펴보고 그 장점이 무엇인지 파악해 보도록 하겠습니다. 예제에 사용할 데이터는 iris 데이터로 R을 설치하면 기본으로 들어있는 데이터 입니다. 세 종류의 iris 품종에 대한 꽃잎과 꽃받침의 length와 with를 측정해 놓은 데이터 입니다. head와 str 명령어를 이용해서 데이터를 살펴 봅니다. %&gt;%를 배웠으니 써보겠습니다. iris %&gt;% head(10) iris %&gt;% str filter의 ,로 구분되는 매개변수는 and 로직으로 묶인 조건입니다. R에서 and는 &amp;, or는 |, 그리고 not은 ! 으로 사용하면 되겠습니다. Image from (https://r4ds.had.co.nz/) head(iris) filter(iris, Species==&quot;setosa&quot;, Species==&quot;versicolor&quot;) filter(iris, Species==&quot;setosa&quot; &amp; Species==&quot;versicolor&quot;) filter(iris, Species==&quot;setosa&quot; | Species==&quot;versicolor&quot;) %&gt;% dim arrange()는 샘플들의 배열 순서 즉, row의 순서를 바꾸는 기능을 수행합니다. arrange(iris, Sepal.Length) arrange(iris, Sepal.Length, Sepal.Width) select() 는 주어진 데이터셋으로부터 관심있는 변수를 선택하여 보여줍니다. 다음 helper 함수들은 select 함수와 같이 유용하게 쓰일 수 있습니다. starts_with(“abc”) - “abc” 로 시작하는 문자열을 갖는 변수 이름 ends_with(“xyz”) - “xyz”으로 끝나는 문자열을 갖는 변수 이름 contains(“ijk”) - “ijk” 문자열을 포함하는 변수 이름 matches(“(.)\\1”) - 정규식, 반복되는 문자 head(iris) select(iris, Species, everything()) select(iris, starts_with(&#39;S&#39;)) select(iris, obs = starts_with(&#39;S&#39;)) iris2 &lt;- rename(iris, aavar = Petal.Length) select(iris2, matches(&quot;(.)\\\\1&quot;)) tmp &lt;-iris[,3:5] colnames(iris)[grep(&quot;^S&quot;, colnames(iris))] iris[,grep(&quot;^S&quot;, colnames(iris))] tmp mutate() 함수는 새로운 변수를 추가할 수 있는 기능을 제공합니다. within()과 비슷하다고 볼 수 있습니다. iris2 &lt;- mutate(iris, sepal_ratio = Sepal.Length/Sepal.Width) head(iris2) summarise()는 data.frame내 특정 변수의 값들로 하나의 요약값/대푯값을 만들어 줍니다. summarise 함수는 단독으로 쓰이기 보다는 group_by() 기능과 병행해서 쓰이는 경우에 유용하게 쓰입니다. summarise_all() 함수를 사용하면 모든 변수에 대해서 지정된 함수를 실행합니다. summarise(iris, mean(Sepal.Length), m=mean(Sepal.Width)) by_species &lt;- group_by(iris, Species) summarise(by_species, mean(Sepal.Width)) summarise_all(by_species, mean) summarise_all(by_species, sd) 위와 같은 dplyr 함수들은 %&gt;%와 같이 사용되어 다중 오퍼레이션을 구현하면 더욱 강력한 효과를 발휘할 수 있습니다. 위에서 구한 품종별 꽃잎과 꽃받침의 평균 길이는 다음과 같이 구현할 수 있습니다. iris %&gt;% group_by(Species) %&gt;% summarise_all(mean) 여러 합수를 중접하여 한 줄로 코딩할 수 있지만 가독성이 떨어지므로 중첩해서 함수를 사용하는 습관은 어떤 프로그래밍 언어에서도 권장하지 않습니다. iris %&gt;% head(10) iris$Species iris_split &lt;- split(iris, iris$Species) iris_split %&gt;% lapply(dim) iris_split %&gt;% lapply(class) colMeans(iris_split[[1]][,-5]) x &lt;- iris_split[[1]] class(x) head(x) colMeans(x) colMeans(x[,-5]) apply(x[,-5], 2, mean) iris_means &lt;- lapply(iris_split, function(x){colMeans(x[,1:4])}) iris_means irisdat &lt;- rbind(iris_means[[1]], iris_means[[2]], iris_means[[3]]) rownames(irisdat) &lt;-names(iris_means) irisdat irisdat &lt;- do.call(rbind, iris_means) iris_means_df &lt;- data.frame(iris_means) iris_means_df barplot(irisdat, beside = T, legend.text = rownames(irisdat)) dplyr의 전신이라 할 수 있는 plyr 패키지는 다음과 같이 설명이 되어 있습니다. A set of tools for a common set of problems: you need to split up a big data structure into homogeneous pieces, apply a function to each piece and then combine all the results back together. 즉 split-apply-combine 세 가지 동작을 쉽게 할 수 있도록 만들어 놓은 툴 입니다. R이 다른 언어에 비해 데이터 분석에서 주목을 받는 이유로 split, apply 등의 행렬 연산 함수가 발달한 것을 내세우는데 dplyr은 이들보다 더 편리하게 데이터 조작을 할 수 있도록 만들어 놓은 것 입니다. [EXERCISE] babies 데이터셋에서 산모의 흡연 여부를 기준으로 아이와, 아이의 엄마, 아빠의 몸무게 데이터에 대한 평균을 구하고 barplot으로 비교하는 분석 실습을 진행하겠습니다. 이 과정에서 split, apply, combine을 활용하여 평균을 구하는 코드와 dplyr 패키지를 사용하여 만든 코드를 비교해 보도록 하겠습니다. 대략적인 분석 프로세스는 다음과 같습니다. 필요 데이터셋 준비 - subset 데이터 클리닝, 변환 - within 그룹별 데이터 분리 - split 대표값 계산 - lapply, apply 계산값 통합 - rbind 그래프 비교 - barplot head(babies) mydat &lt;- subset(babies, select = c(wt, wt1, dwt, smoke)) mydat &lt;- within(mydat, { wt[wt == 999] &lt;- NA wt1[wt1 == 999] &lt;- NA dwt[dwt == 999] &lt;- NA }) mydat &lt;- within(mydat, { smoke = factor(smoke) levels(smoke) = list( &quot;never&quot; = 0, &quot;smoke now&quot; = 1, &quot;until current pregnancy&quot; = 2, &quot;once did, not now&quot; = 3) }) mydat %&gt;% str by_smoke &lt;- split(mydat, mydat$smoke) by_smoke %&gt;% lapply(dim) apply(by_smoke[[1]][,-4], 2, mean, na.rm=T) mysummary &lt;- function(x){ apply(x[,-4], 2, mean, na.rm=T) } mysummary(by_smoke[[1]]) by_smoke_mean &lt;- lapply(by_smoke, mysummary) ## for wt_mean &lt;- do.call(rbind, by_smoke_mean) wt_mean barplot(wt_mean, beside=T, legend.text = rownames(wt_mean), ylim=c(0,200)) #legend(x=1, y=150, legend = rownames(wt_mean)) split은 factor형 변수를 기준으로 데이터를 나누어 주는 역할을 하며 lapply는 list 형 데이터를 각 리스트의 각각의 원소들에 대해서 function(x) 를 수행하는 역할을 합니다. 마지막 rbind를 이용해서 list를 data.frame으로 통합하며 이 때 do.call 함수를 사용할 수도 있습니다. 이제 dplyr 패키지를 이용하여 동일한 기능을 수행해 봅니다. babies %&gt;% str tmp &lt;- babies %&gt;% select(c(wt, wt1, dwt, smoke)) %&gt;% filter(wt!=999, wt1!=999, dwt!=999) %&gt;% mutate(smoke=factor(smoke)) %&gt;% group_by(smoke) %&gt;% summarise_all(mean) tmp 위에서 보듯 dplyr 패키지를 사용할 경우 그 결과는 같으나 코드의 가독성과 효율성면에서 장점을 보여줍니다. 여기서 group_by, summarise_all 함수 등의 자세한 사용법은 help 페이지를 참고해 주세요. 참고로 barplot은 numeric matrix 형태의 입력만을 받으므로 이에 맞도록 데이터를 다시 변형해야 합니다. 후에 배울 ggplot 을 이용하면 이러한 불편함이 없이 data.frame 형 데이터셋도 쉽게 가시화 할 수 있습니다. 5.5 Multivariate graphics - ggplot2 package 데이터 분석에서 데이터를 눈으로 확인하는 것은 중요합니다. 가능하면 raw 데이터를 보면서 크기 비교나 분포를 대략적으로 예측한다면 tool을 사용해서 나오는 결과를 가늠하는 척도가 될 수도 있습니다. 그러나 비교적 큰 데이터의 경우 눈으로 확인하는 것은 한계가 있으므로 그래프나 도표를 그려서 데이터의 분포를 확인하게 됩니다. 5.5.1 Bar graph with basic graph functions Bar graph를 그리기 위한 데이터는 연속형과 범주형으로 나눌 수 있습니다. 아래 예제들은 후에 배울 ggplot의 stat 옵션을 설명하기 위한 예제들로 특정 변수에 대한 그래프를 그릴 때 변수의 값들을 count를 해야할지 아니면 그 값 그대로를 그릴지에 대한 설명을 이해하는데 도움을 줄 있습니다. 첫 번째는 x 변수가 연속형 (continuous)인 경우로 대부분의 경우 bar 그래프는 histogram 을 표현하는데 사용 됩니다. 즉, 특정 구간 내에 포함되는 x의 값의 갯수 (count)를 bar로 표현하는 것 입니다. x &lt;- rnorm(100) hist(x, br=10) head(x) class(x) 두 번째는 하나의 변수 x의 값이 이산형 (discrete) 일 경우에는 x가 갖는 각 값이 몇 개인지를 (count) 나타내기 위해서 bar 그래프를 그릴 수 있을 것 입니다. 아래 코드에서는 x 값 범주의 counting을 위해 table 함수를 사용하였습니다. x &lt;- sample(1:3, 100, replace = T) count_x &lt;- table(x) barplot(count_x) head(x) class(x) count_x barplot(x) 앞서 두 경우가 하나의 x 변수에 대한 값들을 bar graph로 표현한 경우라면 세 번째와 네 번째 경우는 변수가 두 개인 경우라고 볼 수 있습니다. 그 중 세번째 경우로 두 변수 x, y 가 있을 경우 x가 연속형 값을 갖고 y는 각 x 값의 빈도수를 나타내는 상황을 생각할 수 있습니다. 예를 들어 1.212값을 갖는 데이터가 20개이다 라는 상황을 가정할 경우 x=1.212 가 되고 y=20이 됩니다. 이 경우는 앞에서와 같은 카운팅은 필요 없이 x, y 값 그대로를 화면에 그려주면 됩니다. x &lt;- rnorm(10) y &lt;- rnorm(10) plot(x, y, type=&quot;h&quot;) plot(x, y) data.frame(x,y) 마지막으로 앞서와 같이 두 개의 변수로 이루어져 있으나 x가 연속형이 아닌 이산형 변수라는 점이 다릅니다. y는 각 x 값들의 빈도수를 나타내며 이 경우도 x의 빈도수가 y값에 저장되어 있으니 y 값 그대로를 화면에 그려주면 됩니다. x &lt;- 1:3 y &lt;- table(sample(x, 100, replace = T)) y x barplot(y) plot(x=x, y=y, type=&quot;h&quot;) 5.5.2 Bar graph ggplot ggplot의 문법은 간단히 다음과 같습니다. 각 요소들은 레이어 개념으로 생각하면 되며 각 레이어는 + 기호로 줄을 바꿔가며 사용할 수 있습니다. 데이터 지정 (ggplot) 색상, 크기, x축의 값, y축의 값 등 심미적 요소 지정 (aes) 점, 선, 면 등 기하학적 요소 지정 (geoms) 그릴 통계량 지정 (stats) 테마, 스케일 지정 이제 앞서와 같은 4가지 데이터들을 ggplot을 이용하여 차례로 bar graph를 그려 보겠습니다. 간단히 ggplot 함수로 먼저 데이터와 aes로 (미학요소 또는 미적요소) x축 y축 등을 명시하고 + 오퍼레이터를 사용하여 필요한 레이어를 차례로 추가하면서 그래프를 그릴 수 있습니다. 아래 ggplot2를 로딩후 ggplot을 실행할 경우 데이터와 x, y 축만 지정한 상태로 어떤 그래프 (히스토그램인지, 산포도인지 등)를 그릴지 명시되어 있지 않아서 아무것도 그리지 않은 상태의 빈 켄버스만 그려지게 됩니다. library(ggplot2) x &lt;- rnorm(10) y &lt;- rnorm(10) dat &lt;- data.frame(x, y) ggplot(data=dat) ggplot(data=dat, aes(x=x, y=y)) dat + 로 레이어를 추가하면서 geom_bar() 함수로 막대그래프를 그린다고 명시를 하면 되지만 geom_bar의 기본 stat은 count로 data의 y 값은 count 데이터가 아니므로 여전히 빈 화면을 보여줍니다. ggplot(data=dat, aes(x=x, y=y)) + geom_bar() 따라서 stat을 “identity”로 명시하고 그릴 경우 정상적으로 barplot이 그려지게 됩니다. ggplot(data=dat, aes(x=x, y=y)) + geom_bar(stat=&quot;identity&quot;) x가 연속형일 경우 아래와 같이 histogram을 그려 줍니다. continuous 일 경우 stat은 bin으로 하면 특정 범위 안에 있는 값들의 빈도수를 계산하여 히스토그램을 그려줍니다. dat &lt;- data.frame(x1=rnorm(100)) barplot(dat$x1) plot(x=1:length(dat$x1), y=dat$x1, type=&quot;h&quot;) ggplot(dat, aes(x=x1)) + geom_bar(stat=&quot;bin&quot;, bins=30) dat x가 이산형인 경우는 stat을 count로 설정하여 해당 값들의 빈도수를 그려줄 수 있으며 x &lt;- sample(1:3, 100, replace = T) x dat &lt;- data.frame(x=factor(x)) ggplot(dat, aes(x=x)) + geom_bar(stat=&quot;count&quot;) 세 번째, 네 번째 경우 x, y 두 변수에서 y가 x의 빈도수를 저장하고 있을 경우 x가 연속형, 이산형에 상관 없이 stat을 identity로 설정하여 bar graph를 그릴 수 있습니다. x &lt;- rnorm(10) y &lt;- rnorm(10) dat &lt;- data.frame(x, y) ggplot(dat, aes(x=x, y=y)) + geom_bar(stat=&quot;identity&quot;) x1 &lt;- as.factor(1:3) y1 &lt;- tabulate(sample(x1, 100, replace=T)) dat &lt;- data.frame(x1, y1) ggplot(dat, aes(x=x1, y=y1)) + geom_bar(stat=&quot;identity&quot;) ggplot은 다음과 같이 다양한 레이어를 추가하여 필요한 기능을 사용할 수 있습니다. x1 &lt;- as.factor(1:3) y1 &lt;- tabulate(sample(x1, 100, replace=T)) dat &lt;- data.frame(x1, y1) ggplot(dat, aes(x=x1, y=y1, fill=x1)) + geom_bar(stat=&quot;identity&quot;) + guides(fill=FALSE) + xlab(&quot;Discrete cases&quot;) + ylab(&quot;Value&quot;) + ylim(c(0,50))+ ggtitle(&quot;Bar graph for x:discrete and y:value&quot;) 5.5.3 Line graph with ggplot 다음으로 ggplot을 이용한 line graph를 그리는 방법을 알아 봅니다. 앞서 bar graph와의 관계를 보면 line graph는 bar graph의 각 bar에 해당하는 값들을 서로 선으로 이어주는 graph라고 볼 수 있겠습니다. Line graph는 geom_line이라는 함수를 사용해서 그릴 수 있으며 stat의 사용법은 앞서 bar graph와 같습니다. Line graph에서 중요한 점은 아래 group 파라미터 입니다. 선이라는 것은 두 점 이상의 값들을 알 경우에만 연결할 수 있고 ggplot에서는 같은 그룹에 (group) 속해있는 두 개 이상의 값들을 선으로 연결한다는 의미 입니다. 그런데 우리가 가진 데이터 dat 에는 group을 나타내는 변수가 없습니다. 따라서 group=1이라고 할 경우 모든 값들이 같은 1 그룹에 있는 것으로 간주되고 모든 값들을 선으로 연결하는 line 그래프가 그려집니다. bar그래프와 다른 점은 group=1과 geom_bar 대신 geom_line을 사용한 점입니다. 그리고 bar graph의 fill 옵션은 bar의 색을 결정하는 부분으로 line 그래프에서는 bar가 없으므로 사용하지 않습니다. ggplot(dat, aes(x=x1, y=y1, group=1)) + geom_line(stat=&quot;identity&quot;) + guides(fill=FALSE) + xlab(&quot;Discrete cases&quot;) + ylab(&quot;Value&quot;) + ylim(c(0,50))+ ggtitle(&quot;Barplot for x:discrete and y:value&quot;) 추가로 아래와 같이 그려지는 선의 두께를 조절하고 점을 추가로 그려볼 수 있습니다. 점을 그리는 명령어는 geom_point로서 line 과 함께 그리는 것 이므로 + 오퍼레이터를 사용하여 geom_line 과 함께 사용하면 됩니다. ggplot(dat, aes(x=x1, y=y1, group=1)) + geom_line(size=2) + geom_point(size=4, pch=21, fill=&quot;white&quot;) + guides(fill=FALSE) + xlab(&quot;Discrete cases&quot;) + ylab(&quot;Value&quot;) + ylim(c(0,50))+ ggtitle(&quot;Barplot for x:discrete and y:value&quot;) 같은 방법으로 bar 또한 같이 그려줄 수 있습니다. 여기서는 fill 옵션이 geom_bar에 하나 geom_point에 하나씩 쓰였는데 이는 각 geometry에 따라서 필요한 옵션이 다르므로 각각의 geom_xxx 를 사용할 때 상황에 맞게 (help 나 예제를 통해서) 사용하시면 되겠습니다. ggplot(dat, aes(x=x1, y=y1, group=1)) + geom_bar(stat=&quot;identity&quot;, fill=x1) + geom_line(size=2) + geom_point(size=4, pch=21, fill=&quot;white&quot;) + guides(fill=FALSE) + xlab(&quot;Discrete cases&quot;) + ylab(&quot;Value&quot;) + ylim(c(0,50))+ ggtitle(&quot;Barplot for x:discrete and y:value&quot;) 5.5.4 Color, facet, heatmap 다음은 R의 기본 그래픽 함수와 ggplot을 이용한 비교 예제 입니다. library(UsingR) library(dplyr) mycol &lt;- c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;brown&quot;) mydat &lt;- data.frame(Cars93$Price, Cars93$Horsepower, Cars93$Type) head(mydat) mycol2 &lt;- Cars93$Type levels(mycol2) &lt;- mycol mycol3 &lt;- as.character(mycol2) plot(Cars93$Price, Cars93$Horsepower, col=mycol3); legend(x=10, y=300, pch=19, col=levels(mycol2), legend = levels(Cars93$Type)) ggplot 사용, 컬러 지정 ggplot(Cars93, aes(x=Price, y=Horsepower, color=Type)) + geom_point() + scale_color_manual(values=mycol) R에서는 컬러를 지정할 수 있는 다음과 같은 다양한 함수들을 제공합니다. scale_colour_brewer, scale_alpha, scale_colour_gradient, scale_colour_grey, scale_colour_hue, scale_colour_viridis_d 각 함수는 ggplot 명령어와 함께 사용할 수 있으며 자세한 사용법은 도움말을 참고하시기 바랍니다. ggplot(Cars93, aes(x=Price, y=Horsepower, color=Type)) + geom_point() + scale_color_brewer(palette=&quot;Spectral&quot;) color는 태두리의 색을 지정하는 경우이며 fill은 내부의 색을 지정함을 참고하세요. ggplot(Cars93, aes(x=Price, y=Horsepower, fill=Type)) + geom_boxplot() + scale_fill_brewer(palette=&quot;Spectral&quot;) facet_wrap 또는 facet_grid 등의 명령어로 여러 그래프를 그릴 수 있으며 x, y 배치는 formular 형태의 표현식을 사용해서 지정해 줍니다. ggplot(Cars93, aes(x=Price, y=Horsepower, color=Type)) + geom_point() + geom_smooth() + facet_wrap(.~Type, nrow=2) ggplot(Cars93, aes(x=Price, y=Horsepower, color=Type)) + geom_boxplot() 다음과 같이 plot을 특정 변수에 저장하고 + 기호로 추가 레이어를 구성할 수 있으며 facet 그래프에서 scale=“free” 옵션으로 각 판넬의 x 또는 y축에 scale이 다르게 보여지게 할 수 있습니다. p &lt;- Cars93 %&gt;% ggplot(aes(x=Weight, y=MPG.highway)) + geom_point() p &lt;- p + geom_smooth() p p + facet_wrap(~Type, nrow=2) p2 &lt;- p + facet_wrap(~Type, nrow=2, scale=&quot;free&quot;) p2 Heatmap은 geom_tile 함수를 사용하시면 됩니다. library(UsingR) str(Cars93) Cars93 %&gt;% mutate(rescale_price = scale(Horsepower)) %&gt;% ggplot(aes(x=Model, y=Manufacturer)) + geom_tile(aes(fill = rescale_price), colour = &quot;white&quot;) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;steelblue&quot;) 5.5.5 reshape, scaling, tibble row and column names 앞서 5.3.4절에서는 reshape 함수를 이용해서 long 형이나 wide 형의 데이터들을 서로 형태를 전환하는 방법을 배웠습니다. 그러나 reshape 함수보다는 reshape2 패키지의 melt함수를 사용하는 것이 좀 더 직관적이어서 많이 사용되고 있습니다. long 형 데이터의 경우 id, variable, value 세가지 변수만 기억하면 되겠습니다. wide형 데이터를 잘 생각해 보면 id, variable, 그리고 value 이 세가지 요인이 주요 구성 요소임을 알 수 있습니다. data.frame 에 대한 melt 함수의 경우 (help 참고) id.vars 와 measure.vars 파라메터들을 제어해서 사용될 ID나 변수를 선택할 수 있고 value.name을 이용해서 value가 들어갈 변수 이름을 설정할 수 있습니다. 따로 설정하지 않으면 “value”라는 이름으로 저장 됩니다. [EXERCISE] Cars93 데이터에서 numeric 인 변수들만을 뽑아서 별도의 데이터셋을 만들고 NA 제거, Price 기준으로 내림차순 정렬을 수행한 후 상위 30개 데이터만을 가지고 heatmap을 그리시오 library(UsingR) library(dplyr) library(reshape2) str(Cars93) #mydata &lt;- Cars93 %&gt;% select(Price, EngineSize, Horsepower, Length, Wheelbase, Width, Luggage.room, Weight) mydata &lt;- Cars93 %&gt;% select_if(is.numeric) %&gt;% filter(complete.cases(.)) %&gt;% arrange(desc(Price)) %&gt;% mutate(id=factor(1:length(Price))) %&gt;% head(30) mydata_mlt &lt;- melt(mydata, id.vars=&quot;id&quot;) ggplot(mydata_mlt, aes(x=id, y=variable, fill=value)) + geom_tile(colour = &quot;white&quot;) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;steelblue&quot;) head(mydata_mlt) ## boxplot ggplot(mydata_mlt, aes(x=variable, y=value)) + geom_boxplot() 위 그래프는 우리가 원하는대로 그래프가 출력되지 않았습니다. 원인은 스케일이 다르기 때문인데 이는 boxplot을 그려보면 알 수 있습니다. 이에 우선 scaling 을 수행해 보도록 하고 결과를 다시 heatmap을 이용해 표현해 보겠습니다. library(viridis) library(dplyr) library(reshape2) library(UsingR) mydata2 &lt;- Cars93 %&gt;% select_if(is.numeric) %&gt;% filter(complete.cases(.)) %&gt;% apply(2, scale) %&gt;% as.data.frame() %&gt;% arrange(desc(Price)) %&gt;% mutate(id=factor(1:length(Price))) %&gt;% head(30) mydata_mlt2 &lt;- melt(mydata2, id.vars=&quot;id&quot;) p &lt;- ggplot(mydata_mlt2, aes(x=variable, y=id, fill=value)) + geom_tile(colour = &quot;white&quot;) p p + scale_fill_gradient(low = &quot;white&quot;, high = &quot;steelblue&quot;) p + scale_fill_viridis() p &lt;- p + scale_fill_viridis() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) p Cars93 %&gt;% head [EXERCISE] 위 예제에서 id 대신 Cars93 의 Make 변수 값을 사용해서 다시 plot을 그리시오. library(viridis) library(tibble) mydata2 &lt;- Cars93 %&gt;% select(which(sapply(., class)==&quot;numeric&quot; | sapply(., class)==&quot;integer&quot;), Make) %&gt;% filter_all(function(x){!is.na(x)}) %&gt;% mutate_if(is.numeric, function(x){x/sum(x)}) %&gt;% as.data.frame() %&gt;% arrange(desc(Price)) %&gt;% column_to_rownames(&quot;Make&quot;) %&gt;% rownames_to_column() %&gt;% mutate(rowname=factor(rowname, levels=rowname[order(Price)])) %&gt;% head(30) mydata_mlt2 &lt;- melt(mydata2, id.vars=&quot;rowname&quot;) p &lt;- ggplot(mydata_mlt2, aes(x=variable, y=rowname, fill=value)) + geom_tile(colour = &quot;white&quot;) + scale_fill_viridis(name=&quot;Scaled value&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + xlab(&quot;Variables&quot;) + ylab(&quot;Make&quot;) + ggtitle(&quot;&quot;) p "],
["populations.html", "Chapter 6 Populations 6.1 Introduction 6.2 Discrete random variable 6.3 Continuous random variable 6.4 Sampling from a population 6.5 Sampling distribution", " Chapter 6 Populations 6.1 Introduction 강의를 처음 시작할 때 통계의 개념을 설명하면서 다음과 같은 그림을 설명했습니다. 모집단은 우리가 관측할 수 없는 전체집합이고 그 중 샘플링을 통해 샘플의 대표값을 구하고 이 대표값으로 모집단의 대표값이나 분포를 추정하는 것이 통계 입니다. 여기서 새로 등장하는 변수가 확률변수 (Random variable) 입니다. 본 장에서는 이 확률변수의 개념을 확실히 이해하고 이에 따라 확률과 분포의 개념도 정립하도록 합니다. 6.1.1 Random variable 확률변수는 변수와 같지만 데이터가 들어있지 않은 빈 공간으로 보면 되며 population의 데이터가 들어올 가능성만을 갖는 변수로 이해하면 되겠습니다. 즉, population의 어떤 데이터도 샘플링되어 들어갈 수 있지만 아직 들어가 있지 않은 상태이며 따라서 특정 값이 들어갈 수 있는 확률만이 존재해서 확률 변수라고 합니다. 경우의 수는 임의 시행에서 어떤 사건이 일어날 수 있는 가짓수를 말하며 사건 E가 일어날 경우의 수는 \\(n(E)\\) 로 나타냅니다. N을 모든 경우의 수가 일어날 수 있는 가짓수라 할 때 확률의 정의는 아래와 같습니다. \\[ P(E) = \\frac{n(E)}{N} \\] 가짓수를 구할 때 두 사건 A, B가 동시에 일어나지 않는 경우, 즉 사건 A 또는 사건 B가 일어나는 경우의 수는 합의 법칙에 의해 두 경우의 수를 더해주고 두 사건이 동시에 일어날 때, 즉, 사건 A에 연이어 (동시에) 사건 B가 일어나는 경우의 수는 곱의 법칙에 의해 두 경우의 수를 곱해줍니다 . 모든 사건이 동일 확률로 일어나고 총 사건이 한정적이라고 가정하면 다음과 같은 규칙이 적용 됩니다. \\[ \\begin{split} P(E) &amp; &gt; 0 \\\\ \\sum_{All} P(E) &amp; = 1 \\\\ P(A \\text{ OR } B) &amp; = P(A) + P(B) - P(A ~ \\text{AND} ~ B) \\end{split} \\] 여기서 만약 사건 A와 B가 배반사건 일 경우 A 또는 B가 일어날 확률은 \\(P(A) + P(B)\\) 이며 만약 두 사건이 독립일 경우 A와 B가 동시에 일어날 확률은 \\(P(A)p(B)\\) 입니다. 독립이라는 것은 하나의 사건이 일어날 확률이 다른 사건이 일어날 확률에 영향을 주지 않는 경우를 말합니다. [EXERCISE] 다음 예에서 한 사람을 선택할 경우의 확률과 그 사람이 남자일 확률, 어떤 사람이 heavy smoker일 확률, 그리고 남자이거나 heavy smoker 일 확률을 구하시오 tbl &lt;- xtabs(~Sex + Smoke, data=survey) sum(tbl) margin.table(tbl, 1) margin.table(tbl, 2) 위 survey 데이터에서 Univariate 경우만을 생각해 보고 이 때 Random variable 의 개념을 알아봅니다. smoke &lt;- survey$Smoke smoke survey의 smoke를 pupulation 데이터라고 가정하고 \\(X\\)를 해당 population에서 랜덤하게 sampling 한 변수라 하면 (확률 변수) \\(X\\) 가 가질 수 있는 값은 4가지 입니다. 그러나 확률변수는 실제 값을 가지고 있지 않고 확률만을 가질 수 있으므로 \\(P()\\)를 사용하여 \\(P(X)\\) 라고 표현합니다. R 코드를 이용하여 다음 확률들을 구해봅시다. \\[ P(X=\\text{&quot;Never&quot;}) = \\\\ P(X=\\text{&quot;Heavy&quot;}) = \\\\ P(X=\\text{&quot;Occas&quot;}) = \\\\ P(X=\\text{&quot;Regul&quot;}) = \\] smoke &lt;- survey$Smoke smoke table(smoke)/length(smoke) 6.2 Discrete random variable \\(X\\) 를 이산형 확률변수라 하면 \\(X\\)가 가질 수 있는 값은 \\({0, 1, ..}\\) 또는 \\({&quot;yes&quot;, &quot;no&quot;}\\) 등의 이산형 값을 가질 수 있으며 이 값들을 \\(k\\)라 하면 \\(P(X=k)&gt;0\\) 이며 \\(X\\)의 분포는 이러한 확률들을 나열한 것으로 생각하면 됩니다. 즉, 이산형 확률변수 \\(X\\)의 분포는 먼저 가능한 \\(k\\)의 값들을 구한 후 \\(p_k&gt;0\\)이고 \\(\\sum{k}=1\\)인 확률 \\(p_k = P(X=k)\\)의 값을 명시하면 됩니다. [EXERCISE] 동전 한 번 던지기, 가능한 경우의 수는? 확률 변수는? 분포는? \\[ P(X=0) = 1/2 \\\\ P(X=1) = 1/2 \\] [EXERCISE] 주머니에서 공 꺼내기 (G+R=N), 반복 허용해서 두 번 뽑을 때, \\(X\\)를 빨간 공의 갯수라 하면, 가능한 경우의 수는? {0, 1, 2} 분포는? \\[ \\begin{split} P(X=0) &amp; = G/N \\times G/N \\\\ P(X=1) &amp; = R/N \\times G/N + G/N \\times R/N\\\\ P(X=2) &amp; = R/N \\times R/N \\\\ \\end{split} \\] 6.2.1 Probability mass function 그러나 확률 변수의 분포를 언급할 때마다 일일이 확률을 명시할 수 없으므로 이러한 확률을 나타내는 함수를 정의하여 사용할 수 있고 이를 확률 질량 함수 (probability mass function, PMF)라 합니다. [EXERCISE] 앞서 동전 던지는 예제에서 PMF는? \\[ f_X(x) = \\begin{cases} \\frac{1}{2} ~~~~~ \\text{where} ~ x \\in \\{0, 1\\} \\\\ 0 ~~~~~~ \\text{where} ~ x \\notin \\{0, 1\\} \\end{cases} \\] 6.2.2 Mean and standard deviation of discrete R.V. Dataset에서는 평균과 분산이 각각 center와 spread를 나타내는 대표값이였으나 확률 변수에서는 그 정의가 달라집니다. 모평균 (population mean)은 \\(\\mu\\)로 나타내며 확률 변수 \\(X\\)에 대한 평균은 기댓값 (expected value)으로 불리우며 기호로는 다음과 같이 \\(E(X)\\)로 나타낼 수 있습니다. \\[ \\mu = E(X) = \\sum k P(X=k) \\\\ \\] 이는 가중평균으로 모든 \\(k\\) 값들에 대해서 \\(P(X=k)\\)의 가중치를 비율로 곱한 후 더하면 됩니다. 참고로 기댓값은 다음과 같은 선형적 성질을 가지고 있습니다. 가산성 \\(E(X+Y) = E(X) + E(Y)\\) 동차성 \\(E(cX) = cE(X)\\) [EXERCISE] 주사위를 한 번 던질 때 나올 수 있는 주사위의 수의 기댓값을 구하시오 (확률변수 \\(X\\)?, 확률변수의 분포?, 확률변수의 기댓값?) 확률변수: 주사위를 한 번 던질 때 나올 수 있는 주사위의 수 가능한 경우의 수: {1, 2, 3, 4, 5, 6} 확률 변수의 분포: \\[ \\begin{split} P(X=1) &amp; = 1/6 \\\\ P(X=2) &amp; = 1/6 \\\\ P(X=3) &amp; = 1/6 \\\\ P(X=4) &amp; = 1/6 \\\\ P(X=5) &amp; = 1/6 \\\\ P(X=6) &amp; = 1/6 \\\\ \\end{split} \\] PMF: \\[ f_X(x) = \\begin{cases} 1/6 ~~ \\text{where} ~~ x \\in \\{1,2,3,4,5,6\\} \\\\ 0 ~~ \\text{where} ~~ x \\notin \\{1,2,3,4,5,6\\} \\end{cases} \\] 기댓값: 모표준편차는 \\(\\sigma\\)로 표현하며 다음과 같이 정의할 수 있습니다 \\[ \\begin{split} \\sigma^2 &amp; = VAR(X) \\\\ &amp; = E((X-\\mu)^2) \\\\ &amp; = ? \\\\ &amp; = E(X^2) - E(X)^2 \\end{split} \\] 즉, 이 값은 \\((X-\\mu)^2\\)의 기댓값과 같습니다. [EXERCISE] 주머니에서 공 꺼내기 (G+R=N), R을 빨강, G를 녹색 공이라 하고 N을 총 공의 갯수라 하자. 반복을 허용해서 두 번의 공을 뽑을 때 빨간 공의 갯수를 확률변수 \\(X\\)라 하자. 분포는? \\[ P(X=0) = \\\\ P(X=1) = \\\\ P(X=2) = \\] \\(p=R/N, q=G/N\\) 이라 할 경우 기댓값과 분산을 구하시오 \\[ E(X) = \\\\ VAR(X) = \\] 확률 변수 \\(X\\)를 반복을 허용해서 3번의 공을 뽑는 경우에 기댓값과 분산을 구하시오 6.3 Continuous random variable 연속 데이터의 경우에는 \\(P(X=k)\\) 와 같은 개념이 불가능하므로 다른 방식의 확률에 대한 정의가 필요합니다. 이 경우에는 \\(P(a &lt; X \\le b)\\) 와 같은 확률의 범위를 지정하는 방식이 쓰입니다. 이는 \\(F(b) = P(X&lt;b)\\) 함수나 \\(P(a &lt; X \\le b)\\) 와 같은 크기에 해당하는 a, b, 그리고 \\(f(x)\\)로 둘러쌓이는 함수 \\(f(x)\\)로 구현될 수 있습니다. 위 함수 \\(f(x)\\)를 확률변수 \\(X\\)의 밀도라 하며 \\(F(x)\\)와의 관계는 다음 그림과 같습니다. #fx &lt;- function(x, lambda){((lambda^x)*exp(-lambda))/factorial(x)} fx &lt;- function(x, lambda){lambda*exp(-lambda*x)} x &lt;- seq(-1, 5, 0.01) y &lt;- fx(x, 1) plot(x=x, y=y); plot(x=x, y=y, type=&quot;l&quot;); polygon(x=c(1,0,seq(0,1,0.01)), y=c(0, 0, fx(seq(0,1,0.01),1)), col=&quot;red&quot;) 6.3.1 Probability density function 여기서 \\(f(x)\\)는 확률 변수의 분포를 나타내는 함수로써 확률 밀도 함수(probability density function, PDF)라 하고 확률 밀도 함수\\(f(x)\\)와 구간 [a, b]에 대해서 확률변수 X가 구간에 포함될 확률은 \\(P(a &lt; X \\le b)\\)은 \\(\\int^a_b f(x) dx\\) 입니다. 일반적으로 PDF는 다음 두 조건을 만족해야 합니다. 모든 실수값 \\(x\\)에 대해서 \\(f(x) \\ge 0\\) \\(\\int^{\\infty}_{-\\infty} f(x) dx=1\\) 참고로 지수함수는 다음과 같은 PDF를 가집니다. \\[ f_X(x; \\lambda) = \\begin{cases} \\lambda e^{-\\lambda x} ~~~ \\text{where } x \\ge 0 \\\\ 0 ~~~~~~~~~~\\text{where } x &lt; 0 \\end{cases} \\] 또한 확률밀도함수와 누적분포함수 (cumulative density function, CDF) \\(F(x) = P(X \\le x)\\)는 다음과 같은 수식이 성립합니다. \\[ F(x) = \\int^x_{-\\infty} f(x) dx \\\\ f(x) = \\frac{d}{dx} F(x) \\] 6.3.2 Mean and standard deviation of continuous R.V. 연속형 확률변수의 기댓값과 분산은 앞서 이산형의 경우와 같으며 각각 다음과 같이 정의됩니다. \\[ \\begin{split} \\mu = E(X) &amp; = \\int^{\\infty}_{-\\infty} x f(x) dx \\\\ \\sigma^2 = VAR(X) &amp; = E((X-\\mu)^2) \\\\ &amp; = E(X^2) - E(X)^2 \\\\ &amp; = \\int^{\\infty}_{-\\infty} x^2 f(x) dx - {\\int^{\\infty}_{-\\infty} x f(x) dx} ^2 \\end{split} \\] 6.4 Sampling from a population 위와 같은 확률 변수를 사용하는 목적을 우리의 실험을 예를 들어 다시 한번 생각해 보면 실험을 해서 얻는 데이터가 우리가 모르는 모집단으로부터 나오는 것이라 가정하고 최대한 많은 데이터를 확보한 후 그 분포가 모집단의 분포와 같을 것으로 기대하여 기댓값과 분산을 계산하는 것 입니다. 그런데 데이터를 수집하기 전 즉, 실험을 수행하기 전에 도 확률변수를 정의하고 그 확률변수의 기대값을 계산할 수 있고 이는 앞에서 배운바와 같이 이러한 확률변수의 기댓값과 분산이 모집단의 대표값들 입니다. 따라서 모집단에서 표본을 추출 하는 방법이 중요하며 이 때 사용하는 방법이 임의 복원추출 (Random sampling) 입니다. \\(X_1, X_2, X_3, ..., X_n\\)을 모집단에서 뽑은 일련의 확률 변수라 한다면 이들의 분포가 같을 때 identically distributed 되었다고 하며 하나의 확률 변수의 값이 다른 변수들의 분포에 영향을 주지 않을 때 (즉 하나의 확률변수의 값을 알 때 다른 변수들의 분포가 변하지 않을 때) 그 변수는 다른 변수와 independent 하다고 합니다. 이 두 가지 특성을 갖는 표본들을 indepentent and identically distributed 라고 해서 i.i.d.라 부르고 이는 랜덤 샘플링을 할 때 기본이 되는 개념입니다. 예로 하나의 동전을 \\(n\\)번 던질 때 \\(X_i\\)를 i번째 던지는 동전의 앞 또는 뒷면이라 하면 \\(X_1, X_2, ..., X_n\\)은 i.i.d. 입니다. 주머니 공 꺼내기 예제에서 공을 넣고 다시 꺼내는 복원 추출의 경우의 표본들도 마찬가지로 iid 입니다. 그런데 다시 넣지 않고 꺼내는 경우는 어떨까요? [EXERCISE] 3개의 빨간색 공과 2개의 녹색 공이 있는 주머니에서 반복을 허용해서 3개의 공을 뽑을 경우를 생각해 보자. 확률변수 \\(X_i\\)를 \\(i\\)번째 뽑은 공의 색이라 할 때 \\(X_1\\) 의 확률 분포와 \\(X_2\\)의 확률 분포는? 반복을 허용하지 않는 경우의 확률 분포는? R에서는 sample 함수를 사용해서 복원추출 과정을 시뮬레이션 할 수 있습니다. sample(0:1, size=10, replace = T) sample(0:1, size=10, replace = F) sample(0:1, size=1, replace = F) [EXERCISE] 하나의 주사위를 한 번 굴릴 경우 확률변수 \\(X\\)를 나오는 주사위 값이라 하면 \\(X\\)의 기댓값을 구하시오. \\[ \\begin{split} P(X=1) = 1/6 \\\\ P(X=2) = 1/6 \\\\ ... \\\\ E[X] = ? \\end{split} \\] 위에서 구한 기댓값이 실제 나오는지 주사위를 던져서 같은 값이 나오는지를 시뮬레이션하는 코드를 작성하시오. ## analytic solution x &lt;- 1:6 xp &lt;- rep(1/6, 6) sum(x*xp) ## simulation n &lt;- 1000 barx &lt;- rep(0, n) for(i in 1:n){ x &lt;- sample(1:6, size = i, replace=T) barx[i] &lt;- mean(x) } plot(barx) ## simulation 2nd i &lt;- 1:1000 barx2 &lt;- sapply(i, function(x){mean(sample(1:6, size=x, replace=T))}) plot(barx2) [EXERCISE] 3개의 빨간색 공과 2개의 녹색 공이 있는 주머니에서 반복을 허용해서 2개의 공을 뽑을 경우의 확률변수 \\(X\\)를 녹색 공의 갯수라 하자, \\(X\\)의 기댓값과 반복을 허용하지 않고 2개를 뽑을 경우의 기댓값을 구하시오. 또한 위 상황을 시뮬레이션하는 코드를 작성하고 위에서 계산한 기댓값과 같은 값이 나오는지 검증하시오. \\[ \\begin{split} P(X=0) = (3/5)\\times(3/5) = 0.36 \\\\ P(X=1) = (2/5)\\times(3/5) + (3/5) \\times (2/5) = 0.48\\\\ P(X=2) = (2/5) \\times (2/5) = 0.16 \\\\ \\end{split} \\] x &lt;- c(0, 1, 2) xp &lt;- c(0.36, 0.48, 0.16) ex &lt;- sum(x*xp) ex ## 반복 허용하지 않을 경우 \\[ \\begin{split} P(X=0) = (3/5)\\times(2/4) = 0.3 \\\\ P(X=1) = (2/5)\\times(3/4) + (3/5) \\times (2/4) = 0.6 \\\\ P(X=2) = (2/5) \\times (1/4) = 0.1 \\\\ \\end{split} \\] x &lt;- c(0, 1, 2) xp &lt;- c((3/5)*(2/4), (2/5)*(3/4) + (3/5)*(2/4), (2/5)*(1/4)) ex &lt;- sum(x*xp) ex ## 다음은 시뮬레이션 코드입니다. sapply 를 사용한 코드로 변환해 보시기 바랍니다. library(dplyr) n &lt;- 1000 x &lt;- rep(&quot;&quot;, n) pocket &lt;- c(&quot;G&quot;, &quot;G&quot;, &quot;R&quot;, &quot;R&quot;, &quot;R&quot;) #x &lt;- sample(pocket, 2, replace=T) %&gt;% paste(collapse = &quot;&quot;) for(i in 1:n){ x[i] &lt;- sample(pocket, 2, replace=T) %&gt;% paste(collapse = &quot;&quot;) } xtab &lt;- table(x) sum(c(2, 1, 1, 0)*(xtab/sum(xtab))) 6.5 Sampling distribution 통계량(a statistic)은 랜덤 표본을 요약하는 하나의 값입니다. 표본평균이 그 예이며 \\(\\bar{X} = (X_1 + X_2 + ... + X_n)/n\\) 으로 나타낼 수 있습니다. 그런데 통계량이 랜덤 표본에 의존한다면 해당 통계량 또한 확률 변수가 되며 이 통계량의 분포를 표본분포라고 (sample distribution) 합니다. 표본 분포는 복잡한 것으로 알려져 있으나 일반적으로 사용하는 평균이나 분산 등의 통계량에 대해서는 연구가 많이 되어 잘 알려져 있는 편이며 대부분 그들의 모집단과 관련된 값을 가지고 있읍니다. 예를 들어 표본평균의 기댓값과 표준편차는 다음과 같은 값을 가집니다. \\[ E(\\bar{X}) = \\mu_{\\bar{X}} = \\mu \\\\ SD(\\bar{X}) = \\sigma_\\bar{X} = \\frac{\\sigma}{\\sqrt{n}} \\] 즉, 표본평균의 기댓값은 모평균과 같고 표본평균의 표준편차는 모평균의 표준편차와 관계가 있으나 더 작습니다. 이러한 특성 때문에 \\(\\bar{X}\\)를 모평균의 추정에 사용할 수 있습니다. [EXERCISE] 1, 2, 3 세 개의 숫자가 각각 적힌 공이 주머니에 있다. 여기서 하나의 공을 뽑을 때 나오는 숫자를 확률변수 \\(X\\)라 할 때 \\(X\\)의 기댓값과 분산을 구하시오 (공식 이용, 코드 작성). x &lt;- 1:3 xp &lt;- rep(1/3, 3) ex &lt;- sum(x*xp) vx &lt;- sum(x^2*xp) - (sum(x*xp))^2 c(ex, vx) [EXERCISE] 위 예제에서 임의 복원 추출 방법으로 두 개의 표본을 추출하는 경우를 생각해보자. 이 경우 확률변수 \\(X\\)를 두 수의 합을 나타낸다고 가정할 경우 기댓값과 분산을 구하는 코드를 작성하시오. x &lt;- data.frame(x1=rep(1:3, times=3), x2=rep(1:3, each=3)) px &lt;- table(rowSums(x))/length(rowSums(x)) k &lt;- as.numeric(names(px)) ex &lt;- sum(k*px) xp &lt;- sum(k^2*px) - ex^2 c(ex, vx) barplot(px) 위 예제의 경우는 모집단을 알고 있는 경우입니다. 만약 주머니 안에 몇개의 공이 있는지 어떤 수가 써 있는지 모르는 경우를 생각하면 주머니에서 임의 복원 추출을 통해 모수 (모평균)를 추정해야 합니다. 즉 표본평균의 기댓값을 구해야 하므로 임의 복원추출 시행과 그 표본들의 평균을 구하는 여러번의 반복 작업으로 모평균을 추정할 수 있습니다. [EXERCISE] 위 예제에서 주머니 안에 몇 개의 공이 있는지 모른다고 가정하자. 임의 복원 추출 방법으로 \\(n\\)개의 표본을 추출하고 확률변수 \\(X\\)의 기댓값과 분산을 구하시오 6.5.1 Probability distributions 통계에는 다양한 분포들이 존재할 수 있으나 유사한 특성을 갖는 분포들을 분류할 (families of distribution) 수 있고 (https://en.wikipedia.org/wiki/List_of_probability_distributions) 이들 중 잘 알려진 몇 가지 분포들이 많이 연구되고 있습니다. 각 분포는 분포를 결정하는 parameter의 function (PDF, PMF)으로 표현 될 수 있습니다. Discrete random variable Bernoulli distribution Binomial distribution Poisson distribution Continuous random variable Uniform distribution Normal distribution Exponential distribution Lognormal distribution t-distribution chi-squared distribution R에서는 4가지 타입의 분포 정보를 활용할 수 있는 함수를 제공하고 있습니다. “d” 함수는 분포의 PDF/PMF 값 반환 “p” 함수는 분포의 CDF/CMF 값 반환 “q” 함수는 분포의 사분위값 반환 “r” 함수는 분포에서 임의 표본 추출 6.5.2 Bernoulli random variables 확률 변수 X 가 (0, 1) 두 값만을 가질 경우의 확률 분포 (success=1, failure=0) 확률 변수 X의 pmf는 \\(P(X=1) = p\\) 로 나타내며 이 분포는 $ Bernoulli(p) $ 로 타나냄 (파라메터: \\(p\\)) 베르누이 확률 변수의 iid 샘플을 가리켜 (베르누이 시행) Bernoulli trial 이라함 \\[ \\mu = p \\\\ \\sigma^2 = p(1-p) \\] 6.5.3 Binomial random variables 확률변수 X는 \\(n\\)번의 베르누이 시행에서 성공의 개수를 나타냄 이항분포를 나타내는 파라메터는 \\(n\\) 과 성공확률 \\(p\\) 이며 $ Binomial(n, p) $ 로 나타냄 가능한 경우의 수 \\(k=0, 1, 2, .., n\\) 이므로 \\(X\\)의 분포는 \\[ P(X=k) = {n \\choose k} p^k (1-p)^{n-k} \\\\ \\mu = np \\\\ \\sigma^2 = npq \\] [EXERCISE] 동전을 10번 던질 경우 X를 앞면이 나오는 경우의 수라 하면 \\(X=5\\) 일 경우의 확률 \\(P(X=5)\\)와 \\(P(X&lt;6)\\)의 값을 구하시오 [EXERCISE] 하나의 동전을 10번 던질 때 \\(X\\)를 앞면이 나오는 경우의 개수라 하자. 만약 동전이 공평하다면 Binomial(10, 1/2) 분포를 따르게 된다. P(X=5) 값을 구하시오. # from the pdf of binomial r.v. choose(10, 5) * (1/2)^5 * (1/2)^(10-5) # using dbinom function dbinom(5, size=10, prob=1/2) dbinom(0, size=10, prob=1/2) + dbinom(1, size=10, prob=1/2) + dbinom(2, size=10, prob=1/2) + dbinom(3, size=10, prob=1/2) + dbinom(4, size=10, prob=1/2) + dbinom(5, size=10, prob=1/2) sum(dbinom(0:5, size=10, prob=1/2)) ## pdf x&lt;-0:10 x_dist &lt;- choose(10, x) * (1/2)^x * (1/2)^(10-x) x_dist_df &lt;- data.frame(x, x_dist) ggplot(x_dist_df, aes(x=x, y=x_dist)) + geom_bar(stat=&quot;identity&quot;) ggplot을 이용해서 이항분포를 그려봅니다. 히스토그램의 y축은 빈도 수를 나타내지만 이를 확률로 나타낼수도 있고 이 경우 y값은 dbinom의 값과 같습니다. library(ggplot2) library(reshape2) ## pdf x&lt;-0:10 x_dist &lt;- choose(10, x) * (1/2)^x * (1/2)^(10-x) x_dist_df &lt;- data.frame(x, x_dist) ggplot(x_dist_df, aes(x=x, y=x_dist)) + geom_bar(stat=&quot;identity&quot;) x_trials &lt;- rbinom(1000, size=10, prob=1/2) hist(x_trials, br=100) ## distribution ggplot(data.frame(x_trials), aes(x=x_trials)) + geom_bar() x_tab &lt;- table(x_trials) x_df &lt;- data.frame(x_dist, x_tab/sum(x_tab)) x_df2 &lt;- melt(x_df, id.vars=&quot;x_trials&quot;) ggplot(x_df2, aes(x=x_trials, y=value, fill=variable)) + geom_bar(stat=&quot;identity&quot;, position = &quot;dodge&quot;) 위 그래프에서 Freq는 bar로 x_dist는 line으로 나타내 보겠습니다. x_df ggplot(x_df, aes(x=x_trials, y=x_dist)) + geom_bar(stat=&quot;identity&quot;, position = &quot;dodge&quot;) + geom_line(aes(x=as.numeric(x_trials), y=Freq), color=&quot;red&quot;, size=2) + geom_point(aes(x=x_trials, y=Freq), size=3) + scale_y_continuous(sec.axis = sec_axis(~., &quot;Freq&quot;)) 위 예제에서 앞면이 6번 이하로 나올 확률을 구하면 $ P(X 6) = _{k 6} P(X=k) $ 이므로 다음과 같습니다. 따라서 $ P(X 7) = 1- P(X 6)$ 입니다. sum(dbinom(0:6, size=10, prob=1/2)) pbinom(6, size=10, p=1/2) 즉, pbinom을 이용해서 누적함수 분포를 쉽게 그릴 수 있습니다. x &lt;- 0:10 y &lt;- pbinom(x, size=10, p=1/2) dat &lt;- data.frame(x, y) ggplot(dat, aes(x, y)) + geom_point() + geom_line() + geom_bar(stat=&quot;identity&quot;) 6.5.4 Normal random variables 정규확률변수 \\(X\\)의 분포는 연속적인 종모양 (Bell-shaped) 형태를 가진 분포로 pdf상의 y값은 밀도로 해석 정규분포를 나타내는 파라메터는 종모양의 중심인 \\(\\mu\\)와 분산 \\(\\sigma^2\\) 두 개임이며 $ Normal(, ) $ 또는 \\(N(\\mu, \\sigma)\\) 로 나타냄 \\[ f(x|\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{1}{2\\sigma^2} (x-\\mu)^2} \\] 다음은 rnorm과 dnorm을 활용한 예제 입니다. library(ggplot2) n &lt;- 1000 x &lt;- rnorm(n, mean=175, sd=2) xbar &lt;- mean(x) s &lt;- sd(x) xbarsd &lt;- xbar + c(-1, 1)*s hist(x, br=30, probability = T);lines(density(x), col=&quot;red&quot;, lwd=3);abline(v=xbarsd, col=&quot;red&quot;, lwd=3, lty=2) 다음 두 개의 normal desities를 가정해서 그래프를 그려봅시다. 하나는 \\(f(x|\\mu=0, \\sigma=1)\\)이고 다른 하나는 \\(f(x|\\mu=4, \\sigma=1/2)\\) 입니다. x1 &lt;- seq(-4, 4, by=0.1) y1 &lt;- dnorm(x1, mean=0, sd=1) plot(x,y) x2 &lt;- seq(0, 8, by=0.1) y2 &lt;- dnorm(x2, mean=4, sd=0.5) plot(x2, y2) ggplot을 이용해서 두 그래프를 하나의 화면에 그려봅니다. dat &lt;- data.frame(x1, x2, y1, y2) dat ggplot(dat) + geom_line(aes(x1, y1)) + geom_line(aes(x2, y2)) + geom_hline(yintercept = 0) 연속형 확률분포에서 y 값은 특정 x 값에 대한 density라 했고 x의 범위에 대한 면적의 넓이가 확률 입니다. N(0, 1) 분포에서 누적확률 0.5인 곳은 x=0 이며 pnorm 함수로 다음과 같이 확인이 가능합니다. 즉 정규분포에서도 앞서 이항분포에서와 같이 pnorm 함수를 이용해서 누적확률을 구할 수 있습니다. pnorm(0, 0, 1) qnorm은 pnorm의 역함수로 생각하면 되겠습니다. 즉, 정규분포 N(0, 1)에서 확률이 0.5가 되는 곳의 x값을 구하기 위해서는 다음과 같이 코드를 작성하면 되겠습니다. qnorm(0.5, 0, 1) [EXERCISE] N(0, 1) 분포에서 (누적) 확률이 0.95가 되는 곳의 x값을 구하고 그래프를 그린 후 geom_polygon 함수를 이용하여 해당 영역을 색칠 하시오. library(ggplot2, quietly = T) library(reshape2, quietly = T, warn.conflicts = F) ## Warning: package &#39;reshape2&#39; was built under R version 3.5.3 x1 &lt;- seq(-4, 4, by=0.1) y1 &lt;- dnorm(x1, mean=0, sd=1) dat &lt;- data.frame(x1, y1) x.val &lt;- qnorm(0.95, 0, 1) x2 &lt;- seq(-4, x.val, length.out=100) y2 &lt;- dnorm(x2, 0, 1) x2 &lt;- c(x2, x.val) y2 &lt;- c(y2, 0) dat2 &lt;- data.frame(x2, y2) p &lt;- ggplot(dat) + geom_line(aes(x1, y1)) + geom_hline(yintercept = 0) + geom_polygon(data=dat2, aes(x=x2, y=y2)) + geom_vline(xintercept = 0, color=&quot;white&quot;, linetype = &quot;dashed&quot;) p 몇 가지 옵션을 추가한 그래프 입니다. onesd_x &lt;- 1 onesd_y &lt;- dnorm(onesd_x, 0, 1) onesd_dat &lt;- data.frame(x=c(0, onesd_x, onesd_x), y=c(onesd_y, onesd_y, 0)) ## dashed line p &lt;- p + geom_line(data=onesd_dat, aes(x=x, y=y), color=&quot;white&quot;, linetype=&quot;dashed&quot;) ## text label p &lt;- p + annotate(&quot;text&quot;, label = &quot;sd=1&quot;, x = 0.5, y = onesd_y+0.02, size = 5, colour = &quot;red&quot;) ## arrow with text p + labs(title=&quot;Normal distribution with mean 0 and sd 1&quot;, x=&quot;X&quot;, y=&quot;Density&quot;) + theme(plot.title = element_text(size=15, face=&quot;bold.italic&quot;, color=&quot;blue&quot;, hjust=0.5), axis.title.x = element_text(size=15, color=&quot;blue&quot;), axis.title.y = element_text(size=15, color=&quot;blue&quot;)) + geom_segment(aes(x = 2, y = 0.2, xend = x.val, yend = dnorm(x.val, 0, 1)), arrow = arrow(), color=&#39;orange&#39;,size=2) + annotate(&quot;text&quot;, label = paste(&quot;x=&quot;, round(x.val, 3), sep=&quot;&quot;), x = 2, y = 0.22, size = 5, colour = &quot;red&quot;) 다음은 간단히 표준정규분포에서 표본을 추출 한 후 히스토그램과 적합 곡선 (pdf 추정 곡선)을 표현한 그래프 입니다. nsample &lt;- 100 x &lt;- rnorm(nsample) xx &lt;- seq(min(x), max(x), length.out=100) y &lt;- dnorm(xx, mean(x), sd(x)) plot(xx, y) df &lt;- data.frame(x) ggplot(df, aes(x=x)) + geom_histogram(aes(y=..density..)) + geom_density(color=&quot;#FF6666&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. "],
["statistical-inference.html", "Chapter 7 Statistical inference 7.1 Introduction 7.2 Simulation 7.3 Significance tests 7.4 Estimation and confidence interval", " Chapter 7 Statistical inference 7.1 Introduction 통계적 추정이란 모집단으로부터 임의 추출된 표본을 이용하여 모집단을 추정하는 과정을 의미합니다. 앞에서 배운 내용이지만 다음 네 가지 중요한 키워드들이 있습니다. 모집단 (population) 모수 (Parameter) - 모집단의 분포를 설명하는 특정 값 표본 (sample) - 모집단으로부터 임의 추출된 관측값의 모음 통계량 (statistics) - 표본의 평균, 분산과 같은 대표값 다음은 표준정규분포 모집단에서 (모수: \\(\\mu, \\sigma\\)) 16개 표본을 임의 추출하여 평균을 (통계량) \\(\\bar{x}\\) 구하고 이 과정을 10번 반복한 상황을 표현한 그림으로 통계적 추론의 과정을 보여 줍니다. [UsingR for introductory statistics, 243 페이지] 임의 표본에 대해서 \\(\\bar{x}\\)가 \\(\\mu\\) 근처에 분포 임의 표본에 대해서 \\(\\bar{x}\\)의 분산이 \\(\\bar{x}/\\sqrt{n}\\) 로 표현 (표본들의 분산보다 작음) 모분포가 정규분포이면 \\(\\bar{x}\\)도 정규분포 (반복이 많아질수록, 중심극한정리) 시뮬레이션으로 이론 확인 7.2 Simulation [EXERCISE] N(0, 1)의 분포를 dnorm을 이용해 그리시오 (xlim=c(-4,4)) [EXERCISE] 표준정규분포로부터 16개의 표본을 뽑아 평균을 구하고 각 표본과 평균 값들을 y=1 위치에 점으로 표현하시오 (rnorm사용) [EXERCISE] 위 예제를 두 번 반복하되 두 번째 데이터는 y=0.9 위치에 표현하시오 library(ggplot2, quietly = T) nsample &lt;- 16 x &lt;- rnorm(nsample*2, 0, 1) y &lt;- c(rep(1, nsample), rep(0.9, nsample)) g &lt;- factor(c(rep(1, nsample), rep(2, nsample))) dat &lt;- data.frame(x, y, g) ggplot(dat, aes(x, y)) + geom_point() + geom_point(aes(x=mean(x[1:nsample]), y=1), colour=&quot;blue&quot;, size=5, shape=15) + geom_point(aes(x=mean(x[(nsample+1):length(x)]), y=0.9), colour=&quot;blue&quot;, size=5, shape=15) + scale_y_continuous(limits=c(0, 1.2)) [EXERCISE] 위 예제를 10번 반복하되 각 반복 데이터는 각각 y=1, 0.9, 0.8, …, 0.1 위치에 표현하시오 suppressWarnings(suppressMessages(library(ggplot2, quietly = T))) suppressWarnings(suppressMessages(library(dplyr, quietly = T))) nsample &lt;- 16 nrep &lt;- 10 x &lt;- rnorm(nsample*nrep, 0, 1) tmpy &lt;- seq(0.1, 1, length.out=nrep) y &lt;- rep(tmpy, each=nsample) ## ?rep g &lt;- factor(y) dat &lt;- data.frame(x, y, g) dat_mean &lt;- dat %&gt;% group_by(g) %&gt;% summarise(mean=mean(x)) ggplot(dat, aes(x, y)) + geom_point() + scale_y_continuous(limits=c(0, 1.1)) + geom_point(data=dat_mean, aes(y=as.numeric(as.character(g)), x=mean), colour=&quot;blue&quot;, size=5, shape=15) [EXERCISE] 위 예제와 함께 표준정규분포 곡선과 \\(\\bar{x}\\)의 분포를 모두 같이 그리시오 7.3 Significance tests 두 그룹의 데이터 (표본)을 가지고 있을 때 두 그룹이 통계적으로 차이가 있는지를 검증하는 방법으로 (코흐트 데이터, Case-control 데이터) 시뮬레이션에 의한 방법을 먼저 소개하고 이 후 분포를 기준으로 통계적 검증을 알아보겠습니다. 카페인(커피)이 초초한 상태를 유발하는가? 라는 질문에 답하기 위해서 보통 두 그룹의 평균의 차이를 비교합니다. coff &lt;- c(245, 246, 246, 248, 248, 248, 250, 250, 250, 252) nocoff &lt;- c(242, 242, 242, 244, 244, 245, 246, 247, 248, 248) dat &lt;- data.frame(coff, nocoff) obs &lt;- with(dat, mean(coff) - mean(nocoff)) obs ## [1] 3.5 Randomization distribution 상태로 데이터를 다시 두 그룹으로 나누어 차이를 계산하고 이 과정을 반복해서 분포를 그려보겠습니다. [EXERCISE] 두 그룹 데이터에서 임으로 10명을 두 번 뽑아 그 평균의 차이를 계산하시오 [EXERCISE] 위 예제의 과정을 1000번 반복하고 각 차이값의 분포를 그리시오 [EXERCISE] 분포에서 실제 관측한 3.5 값의 위치를 표시하고 관측값보다 더 극단적인 경우가 나올 경우의 비율을 계산하시오 7.4 Estimation and confidence interval 앞서 예제에서 두 그룹간 평균의 차이가 통계량 (statistic) 입니다. 통계량은 모수 (parameter)를 추정하기 위한 값으로 볼 수 있고 이 값이 얼마나 모수와 가까운지, 즉 차이가 0에 가까운지 판단하는 것은 통계적 추정에서 가장 중요한 부분 중 하나 입니다. 일반적으로 \\(\\mu, \\sigma\\) 등 모수는 \\(\\theta\\)로 표현하고 \\(\\theta\\)를 추정하기위한 통계량은 \\(\\hat{\\theta}\\)로 표현합니다. 다음 식으로 우리가 계산한 통계량이 얼마나 믿을만 한지에 대한 판단을 할 수 있습니다. \\[ E((\\hat{\\theta} - \\theta)^2) = VAR(\\hat{\\theta}) + (E(\\hat{\\theta}-\\theta))^2 = \\text{variance} + \\text{bias}^2 \\] 우리가 언급하는 통계량들은 대부분 unbiased 입니다. 불편추정량 (unbiased estimator)이라 부르며 다음과 같은 것들이 있습니다. \\(E(\\bar{x}) = \\mu\\) \\(E(\\bar{p}) = p\\) \\(E(s^2) = \\sigma^2\\) "]
]
