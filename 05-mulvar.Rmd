
# Multivariate data

## Introduction

앞서 장에서는 기본적인 변수에 대한 대표값들과 두 개 이상의 변수가 주어졌을 경우 그 관계를 정량화 하는 과정을 학습했습니다. 그러나 일반적인 데이터 분석은 두 개 이상의 변수와 샘플들에 대해서 정제, 변환, 가시화, 대표값 비교 및 모델링으로 이어지는 단계로 이루어질 수 있습니다. 본 장에서는 R을 사용해서 위 데이터 분석 과정을 수행하기 위해 필요한 프로그래밍 기술을 습득하기 위해 최근 대표적으로 사용되는 dplyr 패키지와 가시화를 위한 ggplot2 package 사용에 대한 학습을 목표로 합니다. 


## Data structures in R

### Vectors 

같은 타입의 데이터를 (Numeric, character, factor, ...) 모아 놓은 컨테이너로서 인덱스는 ```[```, ```]```를 사용합니다. 


### Lists 

앞 장에서 학습한 것처럼 `list` 변수 타입은 `vector` 형태의 여러개의 element를 가질 수 있으며 각 element의 데이터는 문자나 숫자 어떤 데이터 타입도 가능하며 각 element vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 `[` `]`는 리스트를 반환하고 `[[` `]]`는 vector element들을 반환합니다. 


### Matrices

메트릭스는 같은 타입의 데이터로 채워진 사각형 모양을 갖는 컨테이너로 볼 수 있습니다. 인덱스는 ```[i, j]``` 형태로 ```i```는 row, ```j```는 column 을 가리킵니다. 메트릭스의 생성은 ```matrix``` 명령어를 사용하며 다음과 같이 각 column 별로 값을 채워 나가는 것이 기본 설정이며 ```byrow=T``` 를 통해 row를 다 채우고 그 다음 row를 채워 나가게 할 수도 있습니다. 


```{r eval=F}
m <- matrix(c(1,2,3,4), nrow=2)
m
m <- matrix(c(1,2,3,4), nrow=2, byrow = T)
m

```

row와 column 이름은 ```rownames```와 ```colnames```로 설정이 가능하며 ```rbind```와 ```cbind```는 벡터를 연결하고 붙이는 역할을 할 수 있으나 데이터가 많거나 반복해서 수행할 경우 컴퓨터의 리소스를 많이 사용하는 문제로 느려질 수 있습니다. 

```{r, eval=F}
m <- cbind(1:3, c(1.1, 1.2, 1.3), c(1, 1, 2)) # a 3 by 3 matrix
colnames(m) <- c("x", "y", "z") # or cbind(x=..., ...)
m
dim(m)
```

### data.frame

data.frame은 변수들의 집합으로 ```list```형과 비슷하지만 각 변수 element들이 똑같은 길이를 가지고 matrix 형태로 표현되는 것이 다릅니다. 변수들의 이름을 이용하여 ```$``` 기호로 각 변수들의 데이터에 접근 할 수 있고 matrix와 같이 ```[i,j]``` 형태의 인덱싱도 가능합니다.



## Working with data frame I

앞서 잠깐 소개한 것과같이 일반적인 데이터 분석은 데이터 클리닝, 변환, 가시화, 대표값비교, 모델링의 형태로 진행될 수 있습니다. 특히 R에서는 data frame 형태로 대부분의 분석이 진행되므로 data frame 기반의 다양한 데이터 오퍼레이션 기법을 익혀야 합니다. 


### some exercises

```state.x77``` 데이터셋에서 population과 Life Exp, 그리고 Murder 변수만을 이용한 새로운 matrix를 만드시오. 


```{r, eval=F}
str(state.x77)
newstate <- state.x77[,c(1,4,5)]
class(newstate)
str(newstate)
```


위 matrix에 각 주의 이름을 값으로 갖는 새로운 변수 state_name을 추가해 보시오 
```{r, eval=F}
rownames(state.x77)
state_names <- rownames(state.x77)
newstate <- data.frame(state_names, state.x77[,c(1,4,5)])
head(newstate)
str(newstate)
newstate <- data.frame(state_names, state.x77[,c(1,4,5)], stringsAsFactors = F)
str(newstate)
```


newstate data frame의 population과 Life Exp, Murder 변수들의 분포를 boxplot을 이용하여 비교하고 표준화 후 분포가 어떻게 변하는지 설명하시오 

```{r, eval=F}
boxplot(newstate[,-1])

newstate$popstd <- (newstate$Population - mean(newstate$Population))/sd(newstate$Population)
newstate$lifexpstd <- (newstate$Life.Exp - mean(newstate$Life.Exp))/sd(newstate$Life.Exp)
newstate$murderstd <- (newstate$Murder - mean(newstate$Murder))/sd(newstate$Murder)

boxplot(newstate$popstd, newstate$lifexpstd, newstate$murderstd)

```


세 변수간 상관계수를 구하고 관계를 그래프로 나타내시오. 

```{r, eval=F}
cor(newstate$Population, newstate$Life.Exp)
cor(newstate$Population, newstate$Murder)
cor(newstate$Life.Exp, newstate$Murder)

```


### subset and filter

```subset```함수를 이용하면 비교적 쉽게 원하는 조건을 갖는 subset 데이터를 만들 수 있습니다. ```filter``` 함수도 비슷한 기능을 수행합니다. 

```{r, eval=T}
d <- airquality[1:10,]
## subset
d
```

위 데이터셋에서 ```NA```를 제외한 나머지 데이터만으로 새로운 데이터셋을 만들어 봅시다. ```is.na```함수를 사용하면 해당 데이터가 ```NA```인지 ```TRUE``` 또는 ```FALSE``` 를 반환해 줍니다. 


```{r, eval=F}
ds <- d[!is.na(d[,1]),]
ds <- ds[!is.na(ds[,2]),]
ds <- d[!is.na(d[,1]) & !is.na(d[,2]),]
ds <- subset(d, (!is.na(d$Ozone) & !is.na(d$Solar.R)))
ds <- subset(d, complete.cases(d))

ds2 <- filter(d, (!is.na(d$Ozone) & !is.na(d$Solar.R)))
ds2 <- filter(d, complete.cases(d))
```


### transforming

대부분의 R에서 제공하는 함수는 argument로 전달되는 값에 의해 데이터가 바뀌지 않는 ```pure function``` 입니다. 그러나 argument에 의해서 데이터를 바꿀 수 있다면 편리한 경우가 있습니다. 다음 예처럼 ```with``` 또는 ```within``` 함수를 사용하면 argument로 전달되는 데이터가 변형되어 반환될 수 있습니다. 

```{r, eval=F}
d <- airquality
d$Hr <- d$Day*24
with(d, {Day<10})
d <- within(d, {Hr2=Day*24})
d <- transform(d, {Hr3 = Day*24})
```


### reshaping 

보통의 matrix나 data frame 형식의 raw 데이터는 샘플이 row에 나오고 column에는 변수가 위치하는  ```wide``` 형식의 데이터라고 볼 수 있습니다. 즉, 변수가 증가할 때 마다 wide하게 넓어지는 형식이고 그러나 R 기반의 데이터분석이나 모델링을 위해서는 필요에 따라 long 형식의 데이터로 변환할 필요가 있습니다. 이럴 때 주로 사용하는 함수는 ```reshape``` 함수나 ```reshape2``` 패키지의 ```melt``` 함수 입니다. 먼저 reshape 함수의 사용법을 알아 봅니다. reshape의 파라메터 중 direction="wide" 이고 varying 또는 v.names 가 주어지지 않은 경우 idvar나 timevar에 명시된 변수를 제외하고 모두 시간에 따라 변하는 관측된 값이 됩니다. 아래 경우 Expt에 주어진 변수의 값들이 시간에 따라 변하는 값들을 갖는 관측 변수 이름으로 주어지고 idvar에 명시된 변수의 값들은 각 시간별로 관측된 데이터의 id가 됩니다. 

```{r, eval=F}
#library(reshape2)
morley #long
speed_wide <- reshape(morley, idvar = "Run", timevar="Expt", direction="wide")
speed_wide
```

이제 위 wide형 데이터를 long형 데이터로 바꿔보겠습니다. 


```{r, eval=F}
reshape(speed_wide, idvar = "Run", direction = "long")

#wide
df <- data.frame(id = rep(1:4, rep(2,4)),
                 visit = I(rep(c("Before","After"), 4)),
                 x = rnorm(4), y = runif(4))
df
reshape(df, timevar = "visit", idvar = "id", direction = "wide")

#long
df3 <- data.frame(id = 1:4, age = c(40,50,60,50), dose1 = c(1,2,1,2),
                  dose2 = c(2,1,2,1), dose4 = c(3,3,3,3))
df3
reshape(df3, direction = "long", varying = 3:5, sep = "")

```



### merging data 

```merge``` 함수는 두 개 이상의 데이터셋을 통합하는 기능을 수행하는 함수입니다. 이 외에도 ```dplyr``` 패키지의 ```inner_join``` 함수도 많이 쓰이나 이는 이 후 ```dplyr``` 패키지 사용에 대한 내용을 배울 예정입니다. 


UsingR 패키지의 babies 데이터셋에서 missing 값들에 대한 ```NA``` 처리 후 smoke 변수를 factor 형으로 변환한 데이터셋을 만들어 봅니다. 각 변수당 하나씩 처리를 해보고 ```within``` 함수도 사용해 보겠습니다 .

```{r, eval=F}
library(UsingR)
head(babies)

b <- within(babies, {
  gestation[gestation==999] <- NA
  wt[wt == 999] <- NA
})

babies$smoke
b2 <- within(b, {
  smoke = factor(smoke)
  levels(smoke) = list(
    "never" = 0, 
    "smoke now" = 1, 
    "until current pregnancy" = 2,
    "once did, not now" = 3)
  })

fit <- lm(gestation~smoke, b2)
summary(fit)
boxplot(gestation~smoke, b2)

fit <- lm(wt~smoke, b2)
summary(fit)
boxplot(wt~smoke, b2)
```

이제 smoke now 인 경우 또는 나이가 25세 미만인 경우의 샘플에 대해서 subdata를 만들어 봅니다 (subset 함수 사용, id, gestation, age, wt, smok 변수만 사용). 또한 이렇게 만들어진 두 데이터셋을 merge 함수를 이용해서 하나의 데이터셋으로 만들어 봅니다. 

```{r, eval=F}
## merge
b3 <- subset(b2, {smoke=="smoke now"}, c(id, gestation, age, wt, smoke))
b4 <- subset(b2, {age<25}, c(id, gestation, age, wt, smoke))
head(b3)
head(b4)
b.in <- merge(b3, b4, by.x="id", by.y="id", all=FALSE)
b.out <- merge(b3, b4, by.x="id", by.y="id", all=TRUE)
```

### split

```split``` 함수는 데이터 벡터를 주어진 factor 형 값으로 나누는 기능을 하는 함수 입니다. 


```{r, eval=F}
g <- airquality$Month
l <- split(airquality, g)
l1 <- transform(l[[1]], ozz=scale(Ozone))
l1
l2 <- transform(l[[2]], ozz=scale(Ozone))
l2
```




## working with data frame II

앞서 배운 일련의 작업들은 R에서 기본적으로 제공되는 함수를 사용한 경우입니다. 이 외에 R이 갖는 장점인 행렬, 벡터연산 기능을 최대한 활용할 수 있는 기능들에 대한 내용을 배워봅니다. dplyr, reshape2 등의 별도 패키지에대한 설치가 필요합니다.   

### apply 

데이터를 다룰 때 각 원소별, 그룹별, row, column 별로 다뤄야 할 경우가 많으며 apply 계열의 합수는 이러한 기능을 제공하는 함수로써 적절히 사용하면 효율성이나 편리성 뿐만 아니라 코드의 간결성 등 장점이 많은 기능입니다. colMean 과 같은 함수는 column 또는 row 단위로 해당하는 모든 값들에 대해 연산을 수행해주는 함수로 colMean은 평균을 계산하는 함수이고 일반적으로는 다음과 같이 apply 함수와 mean 함수를 이용해서 같은 기능을 수행할 수 있습니다. 


```{r, eval=F}
b5 <- b3[,c(2,3,4)]
colMeans(b5)
colMeans(b5, na.rm=T)


apply(b5, 1, mean)
apply(b5, 2, mean)
apply(b5, 2, mean, na.rm=T)

apply(b5, 2, function(x){ 
  xmean <- mean(x) 
  return(xmean)
  })

apply(b5, 2, sd)
```

임의의 함수를 만들어서 사용할 수도 있습니다. apply 함수를 사용할 경우 행렬이 커질수록 계산 시간도 빨라질 수 있습니다. 

```{r, eval=F}
n <- 1000
m <- matrix(1:n, ncol=10)

mysd <- function(x){
  xmean <- sum(x)/length(x)
  tmpdif <- x-xmean
  xvar <- sum(tmpdif^2)/(length(x)-1)
  xsd <- sqrt(xvar)
  return(xsd)
}

apply(m, 2, mysd)
apply(m, 2, sd)
```

### map and apply function family 

```{r}
# map
collection <- c(4, 9, 16)
Map(sqrt, collection)
sqrt(collection)
sapply(collection, sqrt)

#
lst <- with(ToothGrowth, split(len, supp))
sapply(lst, mean)
sapply(lst, median)
Map(median, lst)

median(lst)
mean(lst)

# mapply
Map(min, c(1,4), c(2,3))
#simplification of output
mapply(min, c(1,4), c(2,3)) 


```



### dplyr - pipe operator

dplyr은 테이블형 데이터를 다루기 위한 도구를 제공하는 매우 편리한 패키지 입니다. ```%>%``` 파이프 오퍼레이터를 사용하여 여러 함수를 연속적으로 사용할 수 있으며 R의 장점 중 하나인 apply와 같은 행렬 연산 기능을 subset, split, group 와 같은 행렬 편집 기능과 더하여 만들어낸 도구라고 할 수 있습니다. 

먼저 파이프 오퍼레이터 ```%>%``` 의 작동법은 간단히 ```%>%```의 왼쪽 코드의 결과를 출력으로 받아 오른쪽 코드의 입력 (첫번째 파라미터의 값)으로 받아들이는 작동을 합니다. 다음 예에서 보면 ```sin(pi)``` 와 같은 함수의 일반적인 사용법 대신  ```pi %>% sin``` 처럼 사용해도 똑같은 결과를 보여줍니다. ```cos(sin(pi))```와 같이 여러 합수를 중첩하여 사용할 경우에도 코드 디자인의 가독성이나 효율 측면에서 크게 향상된 방법을 제공해 줍니다. 


```{r, eval=F}
library(dplyr)

pi %>% sin
sin(pi)
pi %>% sin %>% cos
cos(sin(pi))
```


특히 ``` %>% ```는 이후 설명할 dplyr의 group_by, split, filter, summary 등의 행렬 편집/연산 함수를 빈번히 다양한 조합으로 쓰게되는 상황에서 더 큰 효과를 발휘할 수 있습니다. 그에 앞서 pipe 오퍼레이터의 예제를 좀 더 살펴보겠습니다. 

pipe operator의 왼쪽 구문의 결과가 오른쪽 구문의 입력으로 처리된다고 설명드렸지만 엄밀히 따지면 오른쪽 구문의 첫 번째 파라미터의 입력 값으로 처리되는 것 입니다. 즉, 함수에서 사용되는 파라미터가 여러개일 경우가 있으므로 기본적으로 ``` %>% ``` 의 왼쪽 구문의 출력 값은 오른쪽 구문 (함수)의 첫 번째 인자의 입력값으로 들어가는 것 입니다. 이는 다음 예들을 통해서 명확히 알 수 있습니다. 먼저  ```paste```함수는 그 파라미터로 ```,```로 구분되는 여러개의 입력 값을 가질 수 있습니다. 따라서 다음 코드는 ```x```가 paste의 첫 번째 파라미터로 들어가게 되어 ```"1a", "2a", "3a", "4a", "5a"``` 로 a 앞에 x 값들이 붙어서 출력된 것을 알 수 있습니다. 


```{r, eval=F}
x <- 1:5
x %>% paste("a", sep="")
```

특정 데이터셋의 컬럼별 평균을 구하고 각 평균의 합을 구할 경우를 생각해 봅시다. R에서는 ```colMeans```라는 특별한 함수를 제공하여 컬럼별로 평균을 계산해 줍니다. 그 후 sum 함수를 사용하여 최종 원하는 값을 얻을 수 있습니다. 이러한 코드를 ```%>%``` 오퍼레이터를 사용한 경우의 코드와 비교해 볼 수 있습니다.

```{r, eval=F}
x <- data.frame(x=c(1:100), y=c(201:300))
sum(colMeans(x))

x <- data.frame(x=c(1:100), y=c(201:300))
x %>% colMeans %>% sum
```


그럼 만약 두 번째 또는 다른 위치의 파라미터에 입력으로 왼쪽 구문의 출력을 받아들이고 싶을 경우는 어떻게 할까요? 그럴때는 place holer라는 ```.``` 을 사용하면 되겠습니다. round 함수는 두 개의 파라미터를 가지고 digits 값을 pipe operator로 넘겨주고 싶을 경우 아래와 같이 표현할 수 있습니다. 

```{r, eval=F}
6 %>% round(pi, digits=.)
round(pi, digits=6)
```


### dplyr - Important functions

이제 본격적인 dplyr 함수를 사용해 보겠습니다. dplyr을 구성하는 중요한 함수는 다음 6가지가 있습니다. 

* select() -	select columns
* filter() -	filter rows
* arrange() -	re-order or arrange rows
* mutate() -	create new columns
* summarise() -	summarise values
* group_by() -	allows for group operations in the “split-apply-combine” concept

이 함수들은 ``` %>% ```와 함께 쓰이면서 강력한 성능을 발휘합니다. summarise 함수는 특정 값들의 통계 값을 계산해 주는 함수이며 그 외 5개 함수들은 행렬 편집을 위한 함수들로 보시면 되겠습니다. 각각의 설명보다는 직접 간단한 예제를 수행하면서 각각의 기능을 살펴보고 왜 dplyr이 널리 사용되고 그 장점이 무엇인지 파악해 보도록 하겠습니다. 

예제에 사용할 데이터는 iris 데이터로 R을 설치하면 기본으로 들어있는 데이터 입니다. 세 종류의 iris 품종에 대한 꽃잎과 꽃받침의 length와 with를 측정해 놓은 데이터 입니다. ```head```와 ```str``` 명령어를 이용해서 데이터를 살펴 봅니다. ```%>%```를 배웠으니 써보겠습니다.   

```{r, eval=F}
iris %>% head(10)
iris %>% str
```

데이터를 확인한 후 분석을 시작합니다. 분석은 간단히 각 iris 품종별로 꽃과 꽃받침의 평균을 비교하는 것으로 합니다. 


dplyr의 전신이라 할 수 있는 plyr 패키지는 다음과 같이 설명이 되어 있습니다. *A set of tools for a common set of problems: you need to split up a big data structure into homogeneous pieces, apply a function to each piece and then combine all the results back together.* 즉 split-apply-combine 세 가지 동작을 쉽게 할 수 있도록 만들어 놓은 툴 입니다. R이 다른 언어에 비해 데이터 분석에서 주목을 받는 이유로 split, apply 등의 행렬 연산 함수가 발달한 것을 내세우는데 dplyr은 이들보다 더 편리하게 데이터 조작을 할 수 있도록 만들어 놓은 것 입니다. 


이제 split, apply, combine을 활용하여 평균을 구하는 코드와 dplyr 패키지를 사용하여 만든 코드를 비교해 보도록 하겠습니다. split은 factor형 변수인 Species를 기준으로 iris 데이터를 나누어 주는 역할을 하며 lapply는 list 형 데이터인 iris_split을 각 리스트의 각각의 원소들에 대해서 function(x) 를 수행하는 역할을 합니다. 마지막 data.frame으로 최종 경로를 merge 합니다. 

```{r, eval=F}
iris_split <- split(iris, iris$Species)
iris_means <- lapply(iris_split, function(x){colMeans(x[,1:4])})
iris_means_df <- data.frame(iris_means)
iris_means_df
```

위 코드를 한 줄로 사용하여 최종 iris_means_df 데이터를 를 구한다면 다음과 같이 됩니다. 한눈에 코드가 들어오지 않고 이렇게 중첩해서 함수를 사용하는 습관은 어떤 프로그래밍 언어에서도 권장하지 않습니다. 

```{r, eval=F}
iris_means_df <- data.frame(lapply(split(iris, iris$Species), function(x){colMeans(x[,1:4])}))
```


아래는 dplyr 패키지를 사용한 코드 입니다. 

```{r, eval=F}
iris_means_df2 <- iris %>% group_by(Species) %>% summarise_all(mean)
iris_means_df2
```


위에서 보듯 dplyr 패키지를 사용할 경우 그 결과는 같으나 코드의 가독성과 효율성면에서 장점을 보여줍니다. 여기서 group_by, summarise_all 함수 등의 사용법은 help 페이지를 참고해 주세요. 간단히 iris 데이터를 받아서 Species에 명시된 그룹으로 나누고 mean 함수를 모든 컬럼에 대해서 사용하라는 의미 입니다.



이제 각 평균에 대한 barplot을 그려보도록 하겠습니다. 그런데 barplot은 numeric matrix 형태의 입력만을 받으므로 이에 맞도록 데이터를 다시 변형해야 합니다. 후에 배울 ggplot 을 이용하면 이러한 불편함이 없이 data.frame 형 데이터셋도 쉽게 가시화 할 수 있습니다. 


```{r, eval=F}
barplot(iris_means_df2, beside=T)
iris_means_df2

```


